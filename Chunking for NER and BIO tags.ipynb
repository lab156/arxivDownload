{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag, ne_chunk\n",
    "import nltk.data\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
    "import pickle\n",
    "from collections.abc import Iterable\n",
    "import random\n",
    "from lxml import etree\n",
    "import gzip\n",
    "\n",
    "from nltk.tag import ClassifierBasedTagger\n",
    "from nltk.chunk import ChunkParserI\n",
    "import ner\n",
    "import string\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from unwiki import unwiki\n",
    "from ner.chunker import NamedEntityChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results for the search for definition (currently just Wikipedia)\n",
    "with open('/media/hd1/wikipedia/wiki_definitions_improved.txt', 'r') as wiki_f:\n",
    "    wiki = wiki_f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save and create xml zipped file\n"
     ]
    }
   ],
   "source": [
    "%%script echo Save and create xml zipped file\n",
    "root = etree.Element('root')\n",
    "\n",
    "for line in wiki:\n",
    "    title, section, defin = line.split('-#-%-')\n",
    "    defin = unwiki.loads(eval(defin)).replace('\\n', ' ')\n",
    "    def_tree = etree.Element('definition')\n",
    "    stmnt = etree.SubElement(def_tree, 'stmnt')\n",
    "    stmnt.text = defin\n",
    "    dfndum = etree.SubElement(def_tree, 'dfndum')\n",
    "    dfndum.text = title.strip()\n",
    "    root.append(def_tree)\n",
    "#print(etree.tostring(root, pretty_print=True).decode('utf8')) \n",
    "\n",
    "with gzip.open('/media/hd1/wikipedia/wiki_definitions_improved.xml.gz', 'w') as wiki_fobj:\n",
    "    wiki_fobj.write(etree.tostring(root, pretty_print=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the problematic article is: examples.xml\n",
      "The name of the problematic article is: coding.xml\n",
      "The name of the problematic article is: spaces-pushouts.xml\n",
      "The name of the problematic article is: guide.xml\n",
      "The name of the problematic article is: moduli.xml\n",
      "The name of the problematic article is: more-groupoids.xml\n",
      "The name of the problematic article is: chapters.xml\n",
      "The name of the problematic article is: sets.xml\n",
      "The name of the problematic article is: obsolete.xml\n",
      "The name of the problematic article is: examples-defos.xml\n",
      "The name of the problematic article is: spaces-more-cohomology.xml\n",
      "The name of the problematic article is: bibliography.xml\n",
      "The name of the problematic article is: fdl.xml\n",
      "The name of the problematic article is: limits.xml\n",
      "The name of the problematic article is: conventions.xml\n",
      "The name of the problematic article is: introduction.xml\n",
      "The name of the problematic article is: quot.xml\n",
      "The name of the problematic article is: desirables.xml\n",
      "Found 95 in the stacks dataset.\n"
     ]
    }
   ],
   "source": [
    "def split_fields(elem):\n",
    "    title = elem.find('.//dfndum').text \n",
    "    section = elem.get('name')\n",
    "    defin = elem.find('.//stmnt').text\n",
    "    return (title, section, defin)\n",
    "\n",
    "plmath = []\n",
    "with gzip.open('/media/hd1/planetmath/datasets/planetmath_definitions.xml.gz', 'r') as xml_fobj:\n",
    "    def_xml = etree.parse(xml_fobj)\n",
    "    for art in def_xml.findall('article'):\n",
    "        plmath.append(split_fields(art))\n",
    "stacks = []\n",
    "with gzip.open('/media/hd1/stacks-project/datasets/stacks-definitions.xml.gz', 'r') as xml_fobj:\n",
    "    def_xml = etree.parse(xml_fobj)\n",
    "    for art in def_xml.findall('article'):\n",
    "        try:\n",
    "            stacks.append(split_fields(art))\n",
    "        except AttributeError:\n",
    "            print('The name of the problematic article is: {}'.format(art.attrib['name']))\n",
    "\n",
    "# Print results\n",
    "print('Found {} in the stacks dataset.'.format(len(stacks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('presheaf ',\n",
       "  'sheaves.xml',\n",
       "  ' Let _inline_math_ be a topological space. _item_ A presheaf _inline_math_ of sets on _inline_math_ is a rule which assigns to each open _inline_math_ a set _inline_math_ and to each inclusion _inline_math_ a map _inline_math_ such that _inline_math_ and whenever _inline_math_ we have _inline_math_. _item_ A morphism _inline_math_ of presheaves of sets on _inline_math_ is a rule which assigns to each open _inline_math_ a map of sets _inline_math_ compatible with restriction maps, i.e., whenever _inline_math_ are open the diagram commutes. _item_ The category of presheaves of sets on _inline_math_ will be denoted _inline_math_. ')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(stacks, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hk', 'pp', 'i.e', 'aab', 'u.n', 'scand', 'e.g', '15k', 'p.h.d', 'r.a', 'c.c.c', 'j.a', 'eqs', 'x+2', 'u.s', 'j.w', '62f', 'og', 'pl', 'inc', 'axe', 'etc', 'z-1', 's.t', '2π', 'dr', 'hyp', 'forever—e.g', 'missions', 'ton', 'vibrations', 'eq', 's^2', 'cf', 'ginebra', 'az', 'ex', 'jie', 'resp', 'a.e', 'jr', 'al', 'sow', 'brethren', 'fig', 'spacewalks', 'ca', \"'is\", 'vol', 'mixture', 'wings', 'n.b', 'eng', 'a.k.a', 'juniper', 'sgs', 'mr', 'i.o'}\n"
     ]
    }
   ],
   "source": [
    "# Get data and train the Sentence tokenizer\n",
    "# Uses a standard algorithm (Kiss-Strunk) for unsupervised sentence boundary detection\n",
    "text = ''\n",
    "for i in range(550):\n",
    "    #text += unwiki.loads(eval(wiki[i].split('-#-%-')[2]))\n",
    "    text += plmath[i][2]\n",
    "for i in range(50):\n",
    "    text += stacks[i][2]\n",
    "for i in range(550):\n",
    "    text += unwiki.loads(eval(wiki[i].split('-#-%-')[2]))\n",
    "\n",
    "trainer = PunktTrainer()\n",
    "trainer.INCLUDE_ALL_COLLOCS = True\n",
    "trainer.train(text)\n",
    "tokenizer = PunktSentenceTokenizer(trainer.get_params())\n",
    "print(tokenizer._params.abbrev_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicator function  \n",
      "The indicator function of a subset A of a set X is a function\n",
      "\n",
      "_display_math_\n",
      "\n",
      "defined as\n",
      "\n",
      "_display_math_\n",
      "\n",
      "The Iverson bracket allows the equivalent notation, _inline_math_, to be used instead of _inline_math_.\n",
      "\n",
      "The function _inline_math_ is sometimes denoted _inline_math_, _inline_math_, _inline_math_ or even just _inline_math_. (The Greek letter _inline_math_ appears because it is the initial letter of the Greek word χαρακτήρ, which is the ultimate origin of the word characteristic.)\n",
      "\n",
      "The set of all indicator functions on _inline_math_ can be identified with _inline_math_, the power set of _inline_math_.  Consequently, both sets are sometimes denoted by _inline_math_. This is a special case (_inline_math_) of the notation _inline_math_ for the set of all functions _inline_math_.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  \"The indicator function of a subset \\'\\'A\\'\\' of a set \\'\\'X\\'\\' is a function\\\\n\\\\n:<math>\\\\\\\\mathbf{1}_A \\\\\\\\colon X \\\\\\\\to \\\\\\\\{ 0,1 \\\\\\\\} </math>\\\\n\\\\ndefined as\\\\n\\\\n:<math>\\\\\\\\mathbf{1}_A(x) :=\\\\n\\\\\\\\begin{cases}\\\\n1 &\\\\\\\\text{if } x \\\\\\\\in A, \\\\\\\\\\\\\\\\\\\\n0 &\\\\\\\\text{if } x \\\\\\\\notin A.\\\\n\\\\\\\\end{cases}\\\\n</math>\\\\n\\\\nThe [[Iverson bracket]] allows the equivalent notation, <math>[x\\\\\\\\in A]</math>, to be used instead of <math>\\\\\\\\mathbf{1}_A(x)</math>.\\\\n\\\\nThe function <math>\\\\\\\\mathbf{1}_A</math> is sometimes denoted <math>I_A</math>, <math>\\\\\\\\chi_A</math>, \\'\\'K<sub>A</sub>\\'\\' or even just <math>A</math>. (The [[Greek alphabet|Greek letter]] <math>\\\\\\\\chi</math> appears because it is the initial letter of the Greek word χαρακτήρ, which is the ultimate origin of the word \\'\\'characteristic\\'\\'.)\\\\n\\\\nThe set of all indicator functions on <math>X</math> can be identified with <math>\\\\\\\\mathcal{P}(X)</math>, the [[power set]] of <math>X</math>.  Consequently, both sets are sometimes denoted by <math>2^X</math>. This is a special case (<math>Y =\\\\\\\\{0,1\\\\\\\\}=2</math>) of the notation <math>Y^X</math> for the set of all functions <math>f:X\\\\\\\\to Y </math>.\"\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The cleaning up of the wiki markup so that it looks like normal written english\n",
    "title, section, defin = wiki[850].split('-#-%-')\n",
    "dclean = unwiki.loads(eval(defin))\n",
    "print(title)\n",
    "print(dclean)\n",
    "defin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data and POS and NER tags for each definition (LONG TIME)\n",
    "def put_pos_ner_tags(defl):\n",
    "    def_lst = []\n",
    "    for i in range(len(defl)):\n",
    "        try:\n",
    "            #title, section, defin_raw = wiki[i].split('-#-%-')\n",
    "            #defin_all = unwiki.loads(eval(defin_raw))\n",
    "            title, section, defin_all = defl[i]\n",
    "            for d in tokenizer.tokenize(defin_all):\n",
    "                if title.lower().strip() in d.lower():\n",
    "                    pos_tokens = pos_tag(word_tokenize(d))\n",
    "                    def_ner = ner.bio_tag.bio_tagger(title.strip().split(), pos_tokens)\n",
    "                    other_ner = [((d[0],d[1]),d[2]) for d in def_ner]\n",
    "                    tmp_dict = {'title': title,\n",
    "                               'section': section,\n",
    "                               'defin': d,\n",
    "                               'ner': other_ner}\n",
    "                    def_lst.append(tmp_dict)\n",
    "        except ValueError:\n",
    "            print('parsing error')\n",
    "    return def_lst\n",
    "def_lst = put_pos_ner_tags(stacks) + put_pos_ner_tags(plmath)\n",
    "\n",
    "for i in range(len(wiki)):\n",
    "    try:\n",
    "        title, section, defin_raw = wiki[i].split('-#-%-')\n",
    "        defin_all = unwiki.loads(eval(defin_raw))\n",
    "        for d in tokenizer.tokenize(defin_all):\n",
    "            if title.lower().strip() in d.lower():\n",
    "                pos_tokens = pos_tag(word_tokenize(d))\n",
    "                def_ner = ner.bio_tag.bio_tagger(title.strip().split(), pos_tokens)\n",
    "                other_ner = [((d[0],d[1]),d[2]) for d in def_ner]\n",
    "                tmp_dict = {'title': title,\n",
    "                           'section': section,\n",
    "                           'defin': d,\n",
    "                           'ner': other_ner}\n",
    "                def_lst.append(tmp_dict)\n",
    "    except ValueError:\n",
    "        print('parsing error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Seifert fiber space  ',\n",
       "  'section': '  Definition  ',\n",
       "  'defin': 'A compact Seifert fiber space has only a finite number of exceptional fibers.',\n",
       "  'ner': [(('A', 'DT'), 'O'),\n",
       "   (('compact', 'JJ'), 'O'),\n",
       "   (('Seifert', 'NNP'), 'B-DFNDUM'),\n",
       "   (('fiber', 'NN'), 'I-DFNDUM'),\n",
       "   (('space', 'NN'), 'I-DFNDUM'),\n",
       "   (('has', 'VBZ'), 'O'),\n",
       "   (('only', 'RB'), 'O'),\n",
       "   (('a', 'DT'), 'O'),\n",
       "   (('finite', 'JJ'), 'O'),\n",
       "   (('number', 'NN'), 'O'),\n",
       "   (('of', 'IN'), 'O'),\n",
       "   (('exceptional', 'JJ'), 'O'),\n",
       "   (('fibers', 'NNS'), 'O'),\n",
       "   (('.', '.'), 'O')]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(def_lst,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#training samples = 21148\n",
      "#test samples = 5288\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(def_lst)\n",
    "training_samples = [d['ner'] for d in def_lst[:int(len(def_lst) * 0.8)]]\n",
    "test_samples = [d['ner'] for d in def_lst[int(len(def_lst) * 0.8):]]\n",
    " \n",
    "print(\"#training samples = %s\" % len(training_samples) )   # training samples = 55809\n",
    "print(\"#test samples = %s\" % len(test_samples))            # test samples = 6201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 s, sys: 208 ms, total: 23.2 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "#train the NER Chunking Classifier (TAKES A LONG TIME)\n",
    "%time chunker = NamedEntityChunker(training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  88.4%%\n",
      "    Precision:     25.6%%\n",
      "    Recall:        63.5%%\n",
      "    F-Measure:     36.5%%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the most common metrics on the test dataset\n",
    "unpack = lambda l: [(tok, pos, ner) for ((tok, pos), ner) in l]\n",
    "Tree_lst = [conlltags2tree(unpack(t)) for t in test_samples]\n",
    "print(chunker.evaluate(Tree_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Scores\n",
    "\n",
    "Training with an amount of the dataset and evaluating with the rest\n",
    "* With 80% split of the stacks data:\n",
    "```\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  86.5%%\n",
    "    Precision:     29.0%%\n",
    "    Recall:        60.0%%\n",
    "    F-Measure:     39.1%%\n",
    "```\n",
    "\n",
    "* With 80% of Wiki + Planetmath data:\n",
    "```\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  88.4%%\n",
    "    Precision:     26.5%%\n",
    "    Recall:        66.3%%\n",
    "    F-Measure:     37.9%%\n",
    "```\n",
    "\n",
    "* With 90% of Wiki + Planetmath:\n",
    "```\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  88.7%%\n",
    "    Precision:     27.1%%\n",
    "    Recall:        67.7%%\n",
    "    F-Measure:     38.7%%\n",
    "```\n",
    "\n",
    "* With 90% of the dataset Planetmath data alone:\n",
    "```\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  86.0%%\n",
    "    Precision:     24.0%%\n",
    "    Recall:        67.3%%\n",
    "    F-Measure:     35.3%%\n",
    "```\n",
    "    \n",
    "* With 80% of the dataset\n",
    "\n",
    "* 60% of the data\n",
    "\n",
    "```\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  91.0%%\n",
    "    Precision:     30.7%%\n",
    "    Recall:        63.9%%\n",
    "    F-Measure:     41.5%%\n",
    "```\n",
    "    \n",
    "```\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  90.6%%\n",
    "    Precision:     32.4%%\n",
    "    Recall:        68.7%%\n",
    "    F-Measure:     44.0%%\n",
    "```\n",
    "\n",
    "* 90% of the data\n",
    "\n",
    "```\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  91.2%%\n",
    "    Precision:     32.0%%\n",
    "    Recall:        68.0%%\n",
    "    F-Measure:     43.5%%\n",
    "```\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  We/PRP\n",
      "  define/VBP\n",
      "  a/DT\n",
      "  (DFNDUM Banach/NNP space/NN)\n",
      "  as/IN\n",
      "  a/DT\n",
      "  (DFNDUM complete/JJ vector/NN space/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# An example of a user fed definition\n",
    "print(chunker.parse(pos_tag(word_tokenize(\"We define a Banach space as a complete vector space.\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_metrics(int_range, chunker_fn, data_set = test_samples, print_output=False):\n",
    "    '''\n",
    "    `int_range` is an integer range\n",
    "    NEEDS A TEST_SAMPLES VARIABLE CREATED WHEN SPLITTING THE \n",
    "    TRAINING AND TESTING DATA\n",
    "    Returns two vectors ready to be used in the \n",
    "    metrics classification function\n",
    "    '''\n",
    "    if isinstance(int_range, int):\n",
    "        int_range = [int_range]\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in int_range:\n",
    "        sample = data_set[i]\n",
    "        sm = [s[0] for s in sample]\n",
    "        y_true_tmp = [s[1] for s in sample]\n",
    "        predicted = [v[2] for v in tree2conlltags(chunker_fn.parse(sm))]\n",
    "        y_true += y_true_tmp\n",
    "        y_pred += predicted\n",
    "        if print_output:\n",
    "            for k,s in enumerate(sm):\n",
    "                print('{:15} {:>10}  {:>10}'.format(s[0], y_true_tmp[k], predicted[k]))\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some                     O           O\n",
      "sources                  O           O\n",
      "define                   O           O\n",
      "the                      O           O\n",
      "exponential       B-DFNDUM    B-DFNDUM\n",
      "time              I-DFNDUM    I-DFNDUM\n",
      "hypothesis        I-DFNDUM    I-DFNDUM\n",
      "to                       O           O\n",
      "be                       O           O\n",
      "the                      O           O\n",
      "slightly                 O           O\n",
      "weaker                   O           O\n",
      "statement                O           O\n",
      "that                     O           O\n",
      "3-SAT                    O    B-DFNDUM\n",
      "can                      O           O\n",
      "not                      O           O\n",
      "be                       O           O\n",
      "solved                   O           O\n",
      "in                       O           O\n",
      "time                     O           O\n",
      "_inline_math_            O           O\n",
      ".                        O           O\n"
     ]
    }
   ],
   "source": [
    "OO = prepare_for_metrics(19, chunker, data_set=test_samples, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    B-DFNDUM       0.30      0.74      0.42      5033\n",
      "    I-DFNDUM       0.27      0.82      0.40      3798\n",
      "           O       0.99      0.89      0.94    153037\n",
      "\n",
      "    accuracy                           0.88    161868\n",
      "   macro avg       0.52      0.82      0.59    161868\n",
      "weighted avg       0.95      0.88      0.91    161868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, predicted = prepare_for_metrics(range(len(test_samples)), chunker)\n",
    "print(metrics.classification_report(y_true, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
