{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "1) create a search table with key=term and value paragragh in raw LaTeXML output\n",
    "\n",
    "2) a term-reference is {term, art_addr, parag_index, p_tag, tfidf}\n",
    "\n",
    "3) serialize the list of term-references\n",
    "\n",
    "TODO:\n",
    "- Some `<para>` tags don't have a `<p>` inside so I just used recutext. *ADD* the missing p tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import pickle\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "from marshmallow import Schema, fields, pprint\n",
    "from random import random\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import os, sys, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, os.path.join(parentdir, 'embed'))\n",
    "sys.path.insert(0, parentdir)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from clean_and_token_text import normalize_text, normalize_phrase, join_xml_para_and_write\n",
    "import parsing_xml as px\n",
    "import peep_tar as peep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = 'math20/2003_003'\n",
    "argot_path = '/media/hd1/glossary/NN.v1/' + general_path + '.xml.gz'\n",
    "prom_path = '/media/hd1/promath/' + general_path + '.tar.gz'\n",
    "join_path = '/media/hd1/cleaned_text/joined_math12-34_04-01/' + general_path + 'xml.gz'\n",
    "ns = {'latexml': 'http://dlmf.nist.gov/LaTeXML' }\n",
    "\n",
    "argot = etree.parse(argot_path)\n",
    "with tarfile.open(prom_path) as tar_fobj:\n",
    "    art_lst = [k.get_info()['name'] for k in tar_fobj.getmembers()]\n",
    "    members = tar_fobj.getmembers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ ARGOT 0511_002/math.0511747/math.0511747.xml -------------- \n",
      "b'<definition index=\"74\">\\n      <stmnt> Suppose that _inline_math_ is a complete discrete valuation ring with maximal ideal _inline_math_. Assume, in addition, that _inline_math_ is a field of characteristic _inline_math_. We regard _inline_math_ as a Hausdorff topological ring as in Section by assuming that each _inline_math_ has the discrete topology and then giving _inline_math_ the inverse limit topology. Now define _inline_math_, where the inverse limit is taken over the open normal subgroups _inline_math_ of _inline_math_. (Here each _inline_math_ is given the product topology of a finitely generated free _inline_math_-module.) By construction, _inline_math_. It is also easy to see that nonzero members of _inline_math_ cannot become zero divisors in _inline_math_. </stmnt>\\n    <dfndum>complete discrete valuation</dfndum><dfndum>inverse limit topology</dfndum><dfndum>inverse limit</dfndum><dfndum>generated</dfndum><dfndum>divisors</dfndum></definition>\\n  '\n",
      "-------------- PROMath ------------\n",
      " Suppose that _inline_math_ is a complete discrete valuation ring with maximal ideal _inline_math_. Assume, in addition, that _inline_math_ is a field of characteristic _inline_math_. We regard _inline_math_ as a Hausdorff topological ring as in Section by assuming that each _inline_math_ has the discrete topology and then giving _inline_math_ the inverse limit topology. Now define _inline_math_, where the inverse limit is taken over the open normal subgroups _inline_math_ of _inline_math_. (Here each _inline_math_ is given the product topology of a finitely generated free _inline_math_-module.) By construction, _inline_math_. It is also easy to see that nonzero members of _inline_math_ cannot become zero divisors in _inline_math_. \n",
      "---------------- JOINED math.0511747.xml---------------\n",
      "b'<parag index=\"74\">suppose that _inline_math_ is a complete_discrete_valuation ring with maximal_ideal _inline_math_ assume in addition that _inline_math_ is a_field of characteristic _inline_math_ we regard _inline_math_ as a hausdorff_topological ring as in section by assuming that each _inline_math_ has the discrete_topology and then giving _inline_math_ the inverse_limit_topology now define _inline_math_ where the inverse_limit is taken over the open_normal subgroups _inline_math_ of _inline_math_ here each _inline_math_ is given the_product topology of a finitely_generated free__inline_math__module by construction _inline_math__it is also easy to see that nonzero members of _inline_math_ cannot become zero_divisors in _inline_math_ </parag>'\n"
     ]
    }
   ],
   "source": [
    "def check_sync(parag_index, art_ind_in_argot, general_path_):\n",
    "    argot_path = '/media/hd1/glossary/NN.v1/' + general_path_ + '.xml.gz'\n",
    "    prom_path = '/media/hd1/promath/' + general_path_ + '.tar.gz'\n",
    "    join_path = '/media/hd1/cleaned_text/joined_math12-34_04-01/' +\\\n",
    "                                general_path_ + '.xml.gz'\n",
    "    \n",
    "    # first get the paragraph index from argot\n",
    "    argot_xml = etree.parse(argot_path)\n",
    "    article_ind = argot_xml.getroot()[art_ind_in_argot]\n",
    "    argot_def = article_ind[parag_index]\n",
    "    article_name = article_ind.get('name')\n",
    "    print(f'------------ ARGOT {article_name} -------------- ')\n",
    "    print(etree.tostring(argot_def))\n",
    "    parag_ind = int(argot_def.get('index'))\n",
    "    \n",
    "    #for k,tarobj in enumerate(peep.tar_iter(prom_path, '.xml')):\n",
    "    #    if k == art_ind_in_argot:\n",
    "    \n",
    "    #promath_obj = etree.parse(tarobj[1])\n",
    "    promath_obj = peep.tar(prom_path, article_name)[1].exml\n",
    "    parag = promath_obj.findall('.//latexml:para', namespaces=ns)[parag_ind]\n",
    "    print('-------------- PROMath ------------')\n",
    "    print(px.recutext_xml(parag))\n",
    "    \n",
    "    joined_xml = etree.parse(join_path)\n",
    "    joined_ind = joined_xml.getroot()[art_ind_in_argot+2]\n",
    "    joined_para = joined_ind[parag_ind]\n",
    "    article_name_in_join = joined_ind.get('name')\n",
    "    print(f'---------------- JOINED {article_name_in_join}---------------')\n",
    "    print(etree.tostring(joined_para))\n",
    "    \n",
    "            \n",
    "check_sync(1, 100, 'math05/0511_002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0511_002/math.0511269/math.0511269.xml is empty.\n",
      "0511_002/math.0511040/math.0511040.xml is empty.\n",
      "0511_002/math.0511696/math.0511696.xml is empty.\n",
      "0511_002/math.0511227/math.0511227.xml is empty.\n",
      "0511_002/math.0511379/sextics.xml is empty.\n",
      "0511_002/math.0511063/math.0511063.xml is empty.\n",
      "0511_002/math.0511369/math.0511369.xml is empty.\n",
      "0511_002/math.0511591/misha-note.xml is empty.\n",
      "0511_002/math.0511467/catarxiv.xml is empty.\n",
      "0511_002/math.0511439/heegner.xml is empty.\n",
      "0511_002/math.0511699/math.0511699.xml is empty.\n",
      "0511_002/math.0511220/math.0511220.xml is empty.\n",
      "(\"XML ParseError -- <ExFileObject name='/media/hd1/promath/math05/0511_002.tar.gz'>\", XMLSyntaxError('invalid character in attribute value, line 3502, column 57')) -- On the 0511_002/math.0511061/math.0511061.xml\n",
      "0511_002/math.0511357/GranVanderLinden.xml is empty.\n",
      "0511_002/math.0511702/fragmentation_11_05.xml is empty.\n",
      "0511_002/math.0511279/sga2-smf.xml is empty.\n",
      "0511_002/math.0511563/math.0511563.xml is empty.\n",
      "0511_002/math.0511046/math.0511046.xml is empty.\n",
      "0511_002/math.0511304/plantri4.xml is empty.\n",
      "0511_002/math.0511191/sizes.xml is empty.\n",
      "0511_002/math.0511471/nahm20.xml is empty.\n",
      "0511_002/math.0511491/math.0511491.xml is empty.\n",
      "0511_002/math.0511729/klad.xml is empty.\n",
      "0511_002/math.0511448/monodromie.xml is empty.\n",
      "0511_002/math.0511464/math.0511464.xml is empty.\n",
      "0511_002/math.0511102/penalizationstroisHA.xml is empty.\n",
      "0511_002/math.0511531/mono-poids.xml is empty.\n",
      "0511_002/math.0511633/ejc.xml is empty.\n",
      "0511_002/math.0511155/ade40306.xml is empty.\n",
      "0511_002/math-ph.0511079/dh28xi05.xml is empty.\n",
      "0511_002/math.0511271/spinsl2paper.xml is empty.\n",
      "0511_002/math.0511251/math.0511251.xml is empty.\n",
      "0511_002/math.0511200/fcumul.xml is empty.\n",
      "0511_002/math.0511650/math.0511650.xml is empty.\n",
      "0511_002/math-ph.0511026/math-ph.0511026.xml is empty.\n",
      "0511_002/math.0511590/sydnx.xml is empty.\n",
      "0511_002/math-ph.0511092/BIBANA.xml is empty.\n",
      "0511_002/math.0511246/techreport.xml is empty.\n",
      "0511_002/math.0511420/math.0511420.xml is empty.\n",
      "0511_002/math.0511621/math.0511621.xml is empty.\n",
      "0511_002/math.0511577/representation_final.xml is empty.\n",
      "0511_002/math.0511181/main_a.xml is empty.\n",
      "0511_002/math.0511447/math.0511447.xml is empty.\n",
      "0511_002/math.0511476/math.0511476.xml is empty.\n",
      "0511_002/math.0511423/cartier.xml is empty.\n",
      "0511_002/math.0511006/math.0511006.xml is empty.\n",
      "0511_002/math.0511675/siam.xml is empty.\n",
      "0511_002/math.0511047/math.0511047.xml is empty.\n",
      "{'good': 763, 'empty': 47, 'bad': 1}\n"
     ]
    }
   ],
   "source": [
    "join_xml_para_and_write('/media/hd1/promath/math05/0511_002.tar.gz', '/home/luis/rm_me_tfidf/', lambda s: s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"filename '1501_005/1501.02441/Tiling.xml' not found\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8a09251154b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mget_para\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1501_005/1501.02441/Tiling.xml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-8a09251154b9>\u001b[0m in \u001b[0;36mget_para\u001b[0;34m(art_addr, para, tar_path, run_recutext)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_para\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart_addr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpara\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprom_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_recutext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mxml_fobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar_fobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_fobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpara_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.//latexml:para'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mextractfile\u001b[0;34m(self, member)\u001b[0m\n\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2095\u001b[0;31m             \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmember\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mgetmember\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getmember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filename %r not found\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1783\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"filename '1501_005/1501.02441/Tiling.xml' not found\""
     ]
    }
   ],
   "source": [
    "def get_para(art_addr, para, tar_path=prom_path, run_recutext=True):\n",
    "    # Get a paragraph from an article compressed in a tar file\n",
    "    with tarfile.open(tar_path) as tar_fobj:\n",
    "        xml_fobj = tar_fobj.extractfile(art_addr)\n",
    "        art = etree.parse(xml_fobj)\n",
    "        para_lst = art.findall('.//latexml:para', namespaces=ns)\n",
    "        para_tag = para_lst[para]\n",
    "        #p_tag = etree.tostring(\n",
    "        #    para_tag.find('latexml:p', namespaces=ns)).decode('utf-8')\n",
    "        if run_recutext:\n",
    "            return px.recutext_xml(para_tag)\n",
    "        else:\n",
    "            return etree.tostring(p_tag).decode('utf-8')\n",
    "get_para(\"1501_005/1501.02441/Tiling.xml\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 575/575 [01:08<00:00,  8.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary Key=term and Value=(article_address, parag_index)\n",
    "#results = argot.xpath(\".//dfndum[text()='isothermic']\")\n",
    "#results = argot.xpath(\".//dfndum[contains(text(),'quan')]\")\n",
    "results = argot.xpath(\".//dfndum\")\n",
    "term_pair_dict = defaultdict(list)\n",
    "for r in results:\n",
    "    parent = r.getparent()\n",
    "    para_index = int(parent.get('index'))\n",
    "    grand_parent = parent.getparent()\n",
    "    gparent_name = grand_parent.get('name')\n",
    "    term_pair_dict[normalize_phrase(r.text)].append((gparent_name, para_index))\n",
    "    \n",
    "term_para_dict = defaultdict(list)\n",
    "with tarfile.open(prom_path) as tar_fobj:\n",
    "    for term, pair_lst in tqdm(term_pair_dict.items()):\n",
    "        for pair in pair_lst:\n",
    "            xml_fobj = tar_fobj.extractfile(pair[0])\n",
    "            art = etree.parse(xml_fobj)\n",
    "            para_lst = art.findall('.//latexml:para', namespaces=ns)\n",
    "            para_tag = para_lst[pair[1]]\n",
    "            try:\n",
    "                #p_tag = etree.tostring(\n",
    "                #    para_tag.find('.//latexml:p', namespaces=ns)).decode('utf-8').strip()\n",
    "                p_tag = etree.tostring(\n",
    "                         para_tag).decode('utf-8').strip()\n",
    "            except TypeError as e:\n",
    "                p_tag = px.recutext_xml(para_tag)\n",
    "                print(e)\n",
    "            term_para_dict[term].append((*pair, p_tag))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<dfndum>Locally covariant quantum field</dfndum>'\n",
      "article 1501_005/1501.02682/1501.02682.xml 131\n",
      " Locally covariant quantum field theory _citation_ describes QFT on a category of globally hyperbolic spacetimes _inline_math_. Fixing a spacetime dimension _inline_math_, objects of _inline_math_ are quadruples _inline_math_ where _inline_math_ is a smooth paracompact orientable nonempty _inline_math_-manifold with finitely many connected components, _inline_math_ is a smooth time-orientable metric of signature _inline_math_ on _inline_math_, _inline_math_ and _inline_math_ are choices of orientation and %****␣1501.02682.tex␣Line␣600␣**** time-orientation respectively, 1 The orientation (resp., time-orientation) is conveniently represented as a choice of one of the connected components of the nowhere-zero smooth _inline_math_-forms (resp., _inline_math_-timelike _inline_math_-forms) on _inline_math_. so that the spacetime _inline_math_ is globally hyperbolic. That is, _inline_math_ has no closed causal curves and the intersections _inline_math_ of the causal future of _inline_math_ with the causal past of _inline_math_ is compact (including the possibility of being empty) for any pair of points _inline_math_. A morphism between two objects _inline_math_ and _inline_math_ of _inline_math_ is any smooth embedding _inline_math_ that is isometric, preserves the (time)orientation (i.e., _inline_math_, _inline_math_, _inline_math_) and has a causally convex image. If the image contains a Cauchy surface of _inline_math_, _inline_math_ will be described as a Cauchy morphism. \n",
      "----------------------------\n",
      "b'<dfndum>quantifies the density</dfndum>'\n",
      "article 1501_005/1501.02861/ordinal-embedding-v10-post-BEJ.xml 167\n",
      " Define _inline_math_, which quantifies the density of _inline_math_ in _inline_math_. Because _inline_math_ and _inline_math_ is dense in _inline_math_, we have _inline_math_ as _inline_math_. \n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# search for term containing some text and get the paragraphs (cleaned)\n",
    "results = argot.xpath(\".//dfndum[contains(text(),'quant')]\")\n",
    "with tarfile.open(prom_path) as tar_fobj:\n",
    "    for r in results:\n",
    "        print(etree.tostring(r))\n",
    "        parent = r.getparent()\n",
    "        para_index = int(parent.get('index'))\n",
    "        grand_parent = parent.getparent()\n",
    "        gparent_name = grand_parent.get('name')\n",
    "        print(grand_parent.tag, gparent_name, grand_parent.get('num') )\n",
    "        xml_fobj = tar_fobj.extractfile(gparent_name)\n",
    "        #art = etree.parse(xml_fobj.extractfile())\n",
    "        art = etree.parse(xml_fobj)\n",
    "        para_lst = art.findall('.//latexml:para', namespaces=ns)\n",
    "        print(px.recutext_xml(para_lst[para_index]))\n",
    "        print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TermReference(Schema):\n",
    "    term : str\n",
    "    addr : str\n",
    "    index : int\n",
    "    p_tag : str\n",
    "    tfidf : float = field(default_factory=random)\n",
    "    \n",
    "class TermRefSchema(Schema):\n",
    "    term = fields.String()\n",
    "    addr = fields.String()\n",
    "    index = fields.Int()\n",
    "    p_tag = fields.String()\n",
    "    tfidf = fields.Float()\n",
    "\n",
    "term_ref_lst=[]\n",
    "for term, tup_lst in term_para_dict.items():\n",
    "    for tup in tup_lst:\n",
    "        term_ref_lst.append(TermReference(\n",
    "            term= term,\n",
    "               addr = tup[0],\n",
    "               index = tup[1],\n",
    "              p_tag = tup[2],\n",
    "               tfidf = random()))\n",
    "\n",
    "# Serialize all the data and save to json file\n",
    "trs = TermRefSchema(many=True)\n",
    "with open('/home/luis/rm_me/math_json/'+ general_path + '.json', 'w') as fobj:\n",
    "    fobj.write(trs.dumps(term_ref_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lxml.etree._ElementTree at 0x7f4b7c585600>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
