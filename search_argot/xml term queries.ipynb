{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "1) create a search table with key=term and value paragragh in raw LaTeXML output\n",
    "\n",
    "2) a term-reference is {term, art_addr, parag_index, p_tag, tfidf}\n",
    "\n",
    "3) serialize the list of term-references\n",
    "\n",
    "TODO:\n",
    "- Some `<para>` tags don't have a `<p>` inside so I just used recutext. *ADD* the missing p tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import pickle\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "from marshmallow import Schema, fields, pprint\n",
    "from random import random\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import os, sys, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, os.path.join(parentdir, 'embed'))\n",
    "sys.path.insert(0, parentdir)\n",
    "\n",
    "from clean_and_token_text import normalize_text, normalize_phrase\n",
    "import parsing_xml as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = 'math20/2003_003'\n",
    "argot_path = '/media/hd1/glossary/NN.v1/' + general_path + '.xml.gz'\n",
    "prom_path = '/media/hd1/promath/' + general_path + '.tar.gz'\n",
    "ns = {'latexml': 'http://dlmf.nist.gov/LaTeXML' }\n",
    "\n",
    "argot = etree.parse(argot_path)\n",
    "with tarfile.open(prom_path) as tar_fobj:\n",
    "    art_lst = [k.get_info()['name'] for k in tar_fobj.getmembers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"filename '1501_005/1501.02441/Tiling.xml' not found\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8a09251154b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mget_para\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1501_005/1501.02441/Tiling.xml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-8a09251154b9>\u001b[0m in \u001b[0;36mget_para\u001b[0;34m(art_addr, para, tar_path, run_recutext)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_para\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart_addr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpara\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprom_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_recutext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mxml_fobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar_fobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_fobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpara_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.//latexml:para'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mextractfile\u001b[0;34m(self, member)\u001b[0m\n\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2095\u001b[0;31m             \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmember\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mgetmember\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getmember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filename %r not found\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1783\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"filename '1501_005/1501.02441/Tiling.xml' not found\""
     ]
    }
   ],
   "source": [
    "def get_para(art_addr, para, tar_path=prom_path, run_recutext=True):\n",
    "    with tarfile.open(tar_path) as tar_fobj:\n",
    "        xml_fobj = tar_fobj.extractfile(art_addr)\n",
    "        art = etree.parse(xml_fobj)\n",
    "        para_lst = art.findall('.//latexml:para', namespaces=ns)\n",
    "        para_tag = para_lst[para]\n",
    "        #p_tag = etree.tostring(\n",
    "        #    para_tag.find('latexml:p', namespaces=ns)).decode('utf-8')\n",
    "        if run_recutext:\n",
    "            return px.recutext_xml(para_tag)\n",
    "        else:\n",
    "            return etree.tostring(p_tag).decode('utf-8')\n",
    "get_para(\"1501_005/1501.02441/Tiling.xml\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 575/575 [01:08<00:00,  8.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary Key=term and Value=(article_address, parag_index)\n",
    "#results = argot.xpath(\".//dfndum[text()='isothermic']\")\n",
    "#results = argot.xpath(\".//dfndum[contains(text(),'quan')]\")\n",
    "results = argot.xpath(\".//dfndum\")\n",
    "term_pair_dict = defaultdict(list)\n",
    "for r in results:\n",
    "    parent = r.getparent()\n",
    "    para_index = int(parent.get('index'))\n",
    "    grand_parent = parent.getparent()\n",
    "    gparent_name = grand_parent.get('name')\n",
    "    term_pair_dict[normalize_phrase(r.text)].append((gparent_name, para_index))\n",
    "    \n",
    "term_para_dict = defaultdict(list)\n",
    "with tarfile.open(prom_path) as tar_fobj:\n",
    "    for term, pair_lst in tqdm(term_pair_dict.items()):\n",
    "        for pair in pair_lst:\n",
    "            xml_fobj = tar_fobj.extractfile(pair[0])\n",
    "            art = etree.parse(xml_fobj)\n",
    "            para_lst = art.findall('.//latexml:para', namespaces=ns)\n",
    "            para_tag = para_lst[pair[1]]\n",
    "            try:\n",
    "                #p_tag = etree.tostring(\n",
    "                #    para_tag.find('.//latexml:p', namespaces=ns)).decode('utf-8').strip()\n",
    "                p_tag = etree.tostring(\n",
    "                         para_tag).decode('utf-8').strip()\n",
    "            except TypeError as e:\n",
    "                p_tag = px.recutext_xml(para_tag)\n",
    "                print(e)\n",
    "            term_para_dict[term].append((*pair, p_tag))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<dfndum>Locally covariant quantum field</dfndum>'\n",
      "article 1501_005/1501.02682/1501.02682.xml 131\n",
      " Locally covariant quantum field theory _citation_ describes QFT on a category of globally hyperbolic spacetimes _inline_math_. Fixing a spacetime dimension _inline_math_, objects of _inline_math_ are quadruples _inline_math_ where _inline_math_ is a smooth paracompact orientable nonempty _inline_math_-manifold with finitely many connected components, _inline_math_ is a smooth time-orientable metric of signature _inline_math_ on _inline_math_, _inline_math_ and _inline_math_ are choices of orientation and %****␣1501.02682.tex␣Line␣600␣**** time-orientation respectively, 1 The orientation (resp., time-orientation) is conveniently represented as a choice of one of the connected components of the nowhere-zero smooth _inline_math_-forms (resp., _inline_math_-timelike _inline_math_-forms) on _inline_math_. so that the spacetime _inline_math_ is globally hyperbolic. That is, _inline_math_ has no closed causal curves and the intersections _inline_math_ of the causal future of _inline_math_ with the causal past of _inline_math_ is compact (including the possibility of being empty) for any pair of points _inline_math_. A morphism between two objects _inline_math_ and _inline_math_ of _inline_math_ is any smooth embedding _inline_math_ that is isometric, preserves the (time)orientation (i.e., _inline_math_, _inline_math_, _inline_math_) and has a causally convex image. If the image contains a Cauchy surface of _inline_math_, _inline_math_ will be described as a Cauchy morphism. \n",
      "----------------------------\n",
      "b'<dfndum>quantifies the density</dfndum>'\n",
      "article 1501_005/1501.02861/ordinal-embedding-v10-post-BEJ.xml 167\n",
      " Define _inline_math_, which quantifies the density of _inline_math_ in _inline_math_. Because _inline_math_ and _inline_math_ is dense in _inline_math_, we have _inline_math_ as _inline_math_. \n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# search for term containing some text and get the paragraphs (cleaned)\n",
    "results = argot.xpath(\".//dfndum[contains(text(),'quant')]\")\n",
    "with tarfile.open(prom_path) as tar_fobj:\n",
    "    for r in results:\n",
    "        print(etree.tostring(r))\n",
    "        parent = r.getparent()\n",
    "        para_index = int(parent.get('index'))\n",
    "        grand_parent = parent.getparent()\n",
    "        gparent_name = grand_parent.get('name')\n",
    "        print(grand_parent.tag, gparent_name, grand_parent.get('num') )\n",
    "        xml_fobj = tar_fobj.extractfile(gparent_name)\n",
    "        #art = etree.parse(xml_fobj.extractfile())\n",
    "        art = etree.parse(xml_fobj)\n",
    "        para_lst = art.findall('.//latexml:para', namespaces=ns)\n",
    "        print(px.recutext_xml(para_lst[para_index]))\n",
    "        print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TermReference(Schema):\n",
    "    term : str\n",
    "    addr : str\n",
    "    index : int\n",
    "    p_tag : str\n",
    "    tfidf : float = field(default_factory=random)\n",
    "    \n",
    "class TermRefSchema(Schema):\n",
    "    term = fields.String()\n",
    "    addr = fields.String()\n",
    "    index = fields.Int()\n",
    "    p_tag = fields.String()\n",
    "    tfidf = fields.Float()\n",
    "\n",
    "term_ref_lst=[]\n",
    "for term, tup_lst in term_para_dict.items():\n",
    "    for tup in tup_lst:\n",
    "        term_ref_lst.append(TermReference(\n",
    "            term= term,\n",
    "               addr = tup[0],\n",
    "               index = tup[1],\n",
    "              p_tag = tup[2],\n",
    "               tfidf = random()))\n",
    "\n",
    "# Serialize all the data and save to json file\n",
    "trs = TermRefSchema(many=True)\n",
    "with open('/home/luis/rm_me/math_json/'+ general_path + '.json', 'w') as fobj:\n",
    "    fobj.write(trs.dumps(term_ref_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
