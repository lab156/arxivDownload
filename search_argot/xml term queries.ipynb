{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "1) create a search table with key=term and value paragragh in raw LaTeXML output\n",
    "\n",
    "2) a term-reference is {term, art_addr, parag_index, p_tag, tfidf}\n",
    "\n",
    "3) serialize the list of term-references with the split files from Bridges-2\n",
    "\n",
    "4) Uploading to AWS database, this includes using boto3, dynamodb SDK\n",
    "\n",
    "TODO:\n",
    "- Some `<para>` tags don't have a `<p>` inside so I just used recutext. *ADD* the missing p tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "from marshmallow import Schema, fields, pprint\n",
    "from random import random\n",
    "from dataclasses import dataclass, field\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import boto3 as b3\n",
    "import botocore as bcore\n",
    "from enum import Enum\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import json\n",
    "\n",
    "import os, sys, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, os.path.join(parentdir, 'embed'))\n",
    "sys.path.insert(0, parentdir)\n",
    "sys.path.insert(0, os.path.join(parentdir, \n",
    "                \"slurm_scripts/termreference_db\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from clean_and_token_text import normalize_text, normalize_phrase, join_xml_para_and_write, ReadGlossary\n",
    "import parsing_xml as px\n",
    "import peep_tar as peep\n",
    "import upload_termrefs_to_dynamodb as updyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = 'math20/2003_003'\n",
    "argot_path = '/media/hd1/glossary/NN.v1/' + general_path + '.xml.gz'\n",
    "prom_path = '/media/hd1/promath/' + general_path + '.tar.gz'\n",
    "join_path = '/media/hd1/cleaned_text/joined_math12-34_04-01/' + general_path + 'xml.gz'\n",
    "ns = {'latexml': 'http://dlmf.nist.gov/LaTeXML' }\n",
    "\n",
    "argot = etree.parse(argot_path)\n",
    "with tarfile.open(prom_path) as tar_fobj:\n",
    "    art_lst = [k.get_info()['name'] for k in tar_fobj.getmembers()]\n",
    "    members = tar_fobj.getmembers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2816 [00:00<00:16, 172.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found [2816, 2816] files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2816/2816 [00:52<00:00, 53.16it/s] \n",
      "100%|██████████| 2816/2816 [00:54<00:00, 52.13it/s] \n",
      "100%|██████████| 240/240 [1:06:37<00:00, 16.66s/it]\n"
     ]
    }
   ],
   "source": [
    "#glossary_file_lst = glob.glob('/media/hd1/glossary/NN.v1/math9*/*.xml.gz')\n",
    "glossary_file_lst = glob.glob('/media/hd1/glossary/NN.v1/math0*/*.xml.gz')\n",
    "\n",
    "RG = ReadGlossary('/media/hd1/glossary/v3/math*/*.xml.gz', '/media/hd1/glossary/NN.v1/math*/*')\n",
    "vocab = RG.ntc_intersect('relative')\n",
    "\n",
    "corpus = []\n",
    "term_ref_lst = []\n",
    "for glossary_file in tqdm(glossary_file_lst):\n",
    "    # argot_file format: /media/hd1/glossary/NN.v1/math95/9506_001.xml.gz\n",
    "    math_year = glossary_file.split('/')[-2]\n",
    "    subfilename = glossary_file.split('/')[-1].split('.')[0] # should be 9506_001\n",
    "    promath_file = os.path.join('/media/hd1/promath', math_year, subfilename + '.tar.gz')\n",
    "    joined_file = os.path.join('/media/hd1/cleaned_text/joined_math19-35_13-01/',\n",
    "                               math_year, subfilename + '.xml.gz')\n",
    "    \n",
    "    glossary_xml = etree.parse(glossary_file)\n",
    "    joined_xml = etree.parse(joined_file)\n",
    "    promath_tarfobj = tarfile.open(promath_file)\n",
    "    for art in glossary_xml.findall('./article'):\n",
    "        art_name = art.get('name')\n",
    "        # need to use only the basename of the article\n",
    "        #art_basename = os.path.basename(art_name)\n",
    "        joined_name_results = joined_xml.xpath('./article[@name=\"{}\"]'.format(art_name))\n",
    "        # POPULATE THE CORPUS\n",
    "        if len(joined_name_results) > 0:\n",
    "            joined_art_text = ''\n",
    "            for parag in joined_name_results[0].findall('./parag'):\n",
    "                text = '' if parag.text is None else parag.text\n",
    "                joined_art_text += (text + ' ')\n",
    "            corpus.append(joined_art_text)\n",
    "        else:\n",
    "            print(f'joined name search results empty art_name={art_name}')\n",
    "            corpus.append('')\n",
    "        corpus_index = len(corpus) - 1\n",
    "        \n",
    "        # OPEN THE PROMATH FILE\n",
    "        try:\n",
    "            #promath_obj = peep.tar(promath_file, art_name)[1].exml\n",
    "            promath_obj = px.DefinitionsXML(promath_tarfobj.extractfile(art_name))\n",
    "        except AttributeError:\n",
    "            print(f'{art_name} gave attributeError')\n",
    "        # this list is in sync with glossary paragraph index\n",
    "        promath_parag_lst = promath_obj.para_list()\n",
    "        \n",
    "        # LOOP THROUGH THE DFDUMS\n",
    "        for defin in art.findall('./definition'):\n",
    "            p_index = int(defin.get('index'))\n",
    "            for term_raw in defin.findall('./dfndum'):\n",
    "                term = normalize_text(term_raw.text)\n",
    "                if term in vocab:\n",
    "                    term_ref_lst.append((\n",
    "                           term,\n",
    "                            art_name,\n",
    "                            p_index,\n",
    "                            etree.tostring(promath_parag_lst[p_index]).decode('utf-8'),\n",
    "                            corpus_index))\n",
    "    promath_tarfobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_data_path = '/media/hd1/termreferences/termreference_db17-33_22-01/'\n",
    "with open(pickle_data_path + 'split_pickles/ter_03.pickle', 'rb') as fobj:\n",
    "    term_ref_lst = pickle.load(fobj)\n",
    "#with open(pickle_data_path + 'vocab.pickle', 'rb') as fobj:\n",
    "#    vocab = pickle.load(fobj)\n",
    "#with open(pickle_data_path + 'corpus.pickle', 'rb') as fobj:\n",
    "#    corpus = pickle.load(fobj)\n",
    "#with open(pickle_data_path + 'ttrans.pickle', 'rb') as fobj:\n",
    "#    ttrans = pickle.load(fobj)\n",
    "#with open(pickle_data_path + 'vocab_fixed.pickle', 'rb') as fobj:\n",
    "#    vocab_ = pickle.load(fobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esto tarda 11 min\n"
     ]
    }
   ],
   "source": [
    "%%script echo esto tarda 11 min\n",
    "# COMPUTE THE TDIDF MATRIX\n",
    "vocab_ = list(set([t.replace(' ', '_') for t in vocab]))\n",
    "tvect = TfidfVectorizer(sublinear_tf=True, norm='l1', vocabulary=vocab_)\n",
    "                \n",
    "%time ttrans = tvect.fit_transform(corpus)\n",
    "print(f'The shape of the resulting matrix is: {ttrans.shape}')\n",
    "\n",
    "with open(pickle_data_path + 'ttrans.pickle', 'wb') as fobj:\n",
    "    pickle.dump(ttrans, fobj)\n",
    "    \n",
    "with open(pickle_data_path + 'vocab_fixed.pickle', 'wb') as fobj:\n",
    "    pickle.dump(vocab_, fobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76347426"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tfidf(term_, corpus_index_, vocab_):\n",
    "    ter = term_.replace(' ', '_')\n",
    "    tindex = vocab_.index(ter)\n",
    "    x = ttrans[corpus_index_, tindex]\n",
    "    return int(x * 10_000_000_000)\n",
    "\n",
    "get_tfidf('vertex_of', 315652, vocab_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0612_002/math.0612182/math.0612182.xml', Decimal('125017599')),\n",
       " ('1304_007/1304.4667/1304.4667.xml', Decimal('106511551')),\n",
       " ('0711_002/0711.2775/0711.2775.xml', Decimal('95227573')),\n",
       " ('0806_002/0806.2547/0806.2547.xml', Decimal('88469028')),\n",
       " ('1305_005/1305.2855/1305.2855.xml', Decimal('77125635')),\n",
       " ('1411_002/1411.0803/1411.0803.xml', Decimal('73479893')),\n",
       " ('0205_001/math.0205252/math.0205252.xml', Decimal('72581675')),\n",
       " ('0809_002/0809.2806/0809.2806.xml', Decimal('72452075')),\n",
       " ('0809_002/0809.2806/0809.2806.xml', Decimal('72452073')),\n",
       " ('0611_002/math.0611431/PedramHekmati.xml', Decimal('62418890'))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MAKING QUERIES\n",
    "def get_movie(truid, tfidf, dynamodb=None):\n",
    "    if not dynamodb:\n",
    "        dynamodb = b3.resource('dynamodb', endpoint_url=\"http://localhost:8000\")\n",
    "\n",
    "    table = dynamodb.Table('TermReference2')\n",
    "\n",
    "    try:\n",
    "        response = table.get_item(Key={'truid': truid, \"tfidf\": tfidf})\n",
    "    except bcore.exceptions.ClientError as e:\n",
    "        print(e.response['Error']['Message'])\n",
    "    else:\n",
    "        return response['Item']\n",
    "\n",
    "#res = get_movie(3, 24440)\n",
    "#pprint(res)\n",
    "\n",
    "def query_termreference(term, dynamodb=None, table=\"TermReference\"):\n",
    "    \"\"\"\n",
    "    Finds an exact truid\n",
    "    \"\"\"\n",
    "    if not dynamodb:\n",
    "        dynamodb = boto3.resource('dynamodb', endpoint_url=\"http://localhost:8000\")\n",
    "\n",
    "    table = dynamodb.Table(table)\n",
    "    response = table.query(\n",
    "        KeyConditionExpression=b3.dynamodb.conditions.Key('truid').eq(truid)\n",
    "    )\n",
    "    return response['Items']\n",
    "\n",
    "#res = query_termreference(1005)\n",
    "#pprint(res)\n",
    "#ddb = b3.resource('dynamodb', endpoint_url=\"http://localhost:8000\")\n",
    "ddb = b3.resource('dynamodb', region_name=\"us-east-2\")\n",
    "tab = ddb.Table('TermReference')\n",
    "response = tab.query(\n",
    "    KeyConditionExpression=b3.dynamodb.conditions.Key('term')\\\n",
    "    .eq('lie group'),\n",
    "    ScanIndexForward=False,\n",
    "    Limit=10,\n",
    ")\n",
    "[(r['addr'],r['tfidf']) for r in response['Items']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TableDescription': {'AttributeDefinitions': [{'AttributeName': 'term',\n",
       "    'AttributeType': 'S'},\n",
       "   {'AttributeName': 'tfidf', 'AttributeType': 'N'}],\n",
       "  'TableName': 'TermReference',\n",
       "  'KeySchema': [{'AttributeName': 'term', 'KeyType': 'HASH'},\n",
       "   {'AttributeName': 'tfidf', 'KeyType': 'RANGE'}],\n",
       "  'TableStatus': 'ACTIVE',\n",
       "  'CreationDateTime': datetime.datetime(2022, 1, 29, 12, 58, 41, 393000, tzinfo=tzlocal()),\n",
       "  'ProvisionedThroughput': {'LastIncreaseDateTime': datetime.datetime(1969, 12, 31, 19, 0, tzinfo=tzlocal()),\n",
       "   'LastDecreaseDateTime': datetime.datetime(1969, 12, 31, 19, 0, tzinfo=tzlocal()),\n",
       "   'NumberOfDecreasesToday': 0,\n",
       "   'ReadCapacityUnits': 10,\n",
       "   'WriteCapacityUnits': 10},\n",
       "  'TableSizeBytes': 494142148,\n",
       "  'ItemCount': 46998,\n",
       "  'TableArn': 'arn:aws:dynamodb:ddblocal:000000000000:table/TermReference'},\n",
       " 'ResponseMetadata': {'RequestId': 'd5294f7d-dadc-4afc-9570-61f92d30b83d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sat, 29 Jan 2022 20:04:28 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'x-amz-crc32': '3673605891',\n",
       "   'x-amzn-requestid': 'd5294f7d-dadc-4afc-9570-61f92d30b83d',\n",
       "   'content-length': '598',\n",
       "   'server': 'Jetty(9.4.18.v20190429)'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LIST ALL TABLES\n",
    "#dcl = b3.client('dynamodb', endpoint_url='http://localhost:8000')\n",
    "#dcl.list_tables()['TableNames']\n",
    "\n",
    "# DELETE A TABLE\n",
    "#ddb = b3.resource('dynamodb', endpoint_url='http://localhost:8000')\n",
    "#table = ddb.Table('TermReference')\n",
    "#table.delete()\n",
    "\n",
    "# SCAN A TABLE\n",
    "#ddb = b3.resource('dynamodb', endpoint_url='http://localhost:8000')\n",
    "#table = ddb.Table('TermReference')\n",
    "#table.item_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[9,6])\n",
    "ax = plt.subplot(111)\n",
    "plt.hist([len(tr.p_tag) for tr in TR_lst],100)\n",
    "#ax.get_yaxis().set_major_formatter(\n",
    "#    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ ARGOT 9505_001/math.9505216/math.9505216.xml -------------- \n",
      "b'<definition index=\"15\">\\n      <stmnt> Given _inline_math_, _inline_math_ is in _inline_math_ if the following is true. _inline_math_ is a disjoint decomposition. _inline_math_ and _inline_math_ are in _inline_math_ where _inline_math_, _inline_math_. There is _inline_math_, an isomorphism between _inline_math_ and _inline_math_. _inline_math_ is the identity. For _inline_math_ the sets _inline_math_ and _inline_math_ are isomorphic. _inline_math_. _inline_math_ is one-to-one and takes only values outside _inline_math_ (which is the same as _inline_math_). _inline_math_. We make _inline_math_ and the ordering on _inline_math_ is the one generated by this. </stmnt>\\n    <dfndum>disjoint decomposition</dfndum><dfndum>isomorphic</dfndum><dfndum>one-to-one</dfndum></definition>\\n  '\n",
      "-------------- PROMath ------------\n",
      " Given _inline_math_, _inline_math_ is in _inline_math_ if the following is true. _inline_math_ is a disjoint decomposition. _inline_math_ and _inline_math_ are in _inline_math_ where _inline_math_, _inline_math_. There is _inline_math_, an isomorphism between _inline_math_ and _inline_math_. _inline_math_ is the identity. For _inline_math_ the sets _inline_math_ and _inline_math_ are isomorphic. _inline_math_. _inline_math_ is one-to-one and takes only values outside _inline_math_ (which is the same as _inline_math_). _inline_math_. We make _inline_math_ and the ordering on _inline_math_ is the one generated by this. \n",
      "---------------- JOINED math.9505216.xml---------------\n",
      "b'<parag index=\"15\">given _inline_math_ _inline_math_ is in _inline_math_ if the following is true _inline_math_ is a disjoint_decomposition _inline_math_ and _inline_math_ are in _inline_math_ where _inline_math_ _inline_math_ there is _inline_math_ an isomorphism between _inline_math_ and _inline_math_ _inline_math_ is the identity for _inline_math_ the sets _inline_math_ and _inline_math_ are isomorphic _inline_math_ _inline_math_ is one_to_one and takes only values outside _inline_math_ which is the same as _inline_math_ _inline_math_ we make _inline_math_ and the ordering on _inline_math_ is the one_generated by this </parag>'\n"
     ]
    }
   ],
   "source": [
    "# check if it is possible to find the same paragraph in promath, argot-glossary, joined\n",
    "def check_sync(parag_index, art_ind_in_argot, general_path_):\n",
    "    argot_path = '/media/hd1/glossary/NN.v1/' + general_path_ + '.xml.gz'\n",
    "    prom_path = '/media/hd1/promath/' + general_path_ + '.tar.gz'\n",
    "    join_path = '/media/hd1/cleaned_text/joined_math12-34_04-01/' +\\\n",
    "                                general_path_ + '.xml.gz'\n",
    "    \n",
    "    # first get the paragraph index from argot\n",
    "    argot_xml = etree.parse(argot_path)\n",
    "    article_ind = argot_xml.getroot()[art_ind_in_argot]\n",
    "    argot_def = article_ind[parag_index]\n",
    "    article_name = article_ind.get('name')\n",
    "    print(f'------------ ARGOT {article_name} -------------- ')\n",
    "    print(etree.tostring(argot_def))\n",
    "    parag_ind = int(argot_def.get('index'))\n",
    "    \n",
    "    #for k,tarobj in enumerate(peep.tar_iter(prom_path, '.xml')):\n",
    "    #    if k == art_ind_in_argot:\n",
    "    \n",
    "    #promath_obj = etree.parse(tarobj[1])\n",
    "    promath_obj = peep.tar(prom_path, article_name)[1].exml\n",
    "    parag = promath_obj.findall('.//latexml:para', namespaces=ns)[parag_ind]\n",
    "    print('-------------- PROMath ------------')\n",
    "    print(px.recutext_xml(parag))\n",
    "    \n",
    "    joined_xml = etree.parse(join_path)\n",
    "    art_basename = article_name.split('/')[-1]\n",
    "    joined_ind = joined_xml.xpath('./article[@name=\"{}\"]'.format(art_basename))[0]\n",
    "    joined_para = joined_ind[parag_ind]\n",
    "    article_name_in_join = joined_ind.get('name')\n",
    "    print(f'---------------- JOINED {article_name_in_join}---------------')\n",
    "    print(etree.tostring(joined_para))\n",
    "            \n",
    "check_sync(1, 5, 'math95/9505_001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 575/575 [01:08<00:00,  8.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary Key=term and Value=(article_address, parag_index)\n",
    "#results = argot.xpath(\".//dfndum[text()='isothermic']\")\n",
    "#results = argot.xpath(\".//dfndum[contains(text(),'quan')]\")\n",
    "results = argot.xpath(\".//dfndum\")\n",
    "term_pair_dict = defaultdict(list)\n",
    "for r in results:\n",
    "    parent = r.getparent()\n",
    "    para_index = int(parent.get('index'))\n",
    "    grand_parent = parent.getparent()\n",
    "    gparent_name = grand_parent.get('name')\n",
    "    term_pair_dict[normalize_phrase(r.text)].append((gparent_name, para_index))\n",
    "    \n",
    "term_para_dict = defaultdict(list)\n",
    "with tarfile.open(prom_path) as tar_fobj:\n",
    "    for term, pair_lst in tqdm(term_pair_dict.items()):\n",
    "        for pair in pair_lst:\n",
    "            xml_fobj = tar_fobj.extractfile(pair[0])\n",
    "            art = etree.parse(xml_fobj)\n",
    "            para_lst = art.findall('.//latexml:para', namespaces=ns)\n",
    "            para_tag = para_lst[pair[1]]\n",
    "            try:\n",
    "                #p_tag = etree.tostring(\n",
    "                #    para_tag.find('.//latexml:p', namespaces=ns)).decode('utf-8').strip()\n",
    "                p_tag = etree.tostring(\n",
    "                         para_tag).decode('utf-8').strip()\n",
    "            except TypeError as e:\n",
    "                p_tag = px.recutext_xml(para_tag)\n",
    "                print(e)\n",
    "            term_para_dict[term].append((*pair, p_tag))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"filename '1501_005/1501.02441/Tiling.xml' not found\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8a09251154b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mget_para\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1501_005/1501.02441/Tiling.xml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-8a09251154b9>\u001b[0m in \u001b[0;36mget_para\u001b[0;34m(art_addr, para, tar_path, run_recutext)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_para\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart_addr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpara\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprom_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_recutext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mxml_fobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar_fobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_fobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpara_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.//latexml:para'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mextractfile\u001b[0;34m(self, member)\u001b[0m\n\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2095\u001b[0;31m             \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmember\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mgetmember\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getmember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filename %r not found\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1783\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"filename '1501_005/1501.02441/Tiling.xml' not found\""
     ]
    }
   ],
   "source": [
    "def get_para(art_addr, para, tar_path=prom_path, run_recutext=True):\n",
    "    # Get a paragraph from an article compressed in a tar file\n",
    "    with tarfile.open(tar_path) as tar_fobj:\n",
    "        xml_fobj = tar_fobj.extractfile(art_addr)\n",
    "        art = etree.parse(xml_fobj)\n",
    "        para_lst = art.findall('.//latexml:para', namespaces=ns)\n",
    "        para_tag = para_lst[para]\n",
    "        #p_tag = etree.tostring(\n",
    "        #    para_tag.find('latexml:p', namespaces=ns)).decode('utf-8')\n",
    "        if run_recutext:\n",
    "            return px.recutext_xml(para_tag)\n",
    "        else:\n",
    "            return etree.tostring(p_tag).decode('utf-8')\n",
    "get_para(\"1501_005/1501.02441/Tiling.xml\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<dfndum>Locally covariant quantum field</dfndum>'\n",
      "article 1501_005/1501.02682/1501.02682.xml 131\n",
      " Locally covariant quantum field theory _citation_ describes QFT on a category of globally hyperbolic spacetimes _inline_math_. Fixing a spacetime dimension _inline_math_, objects of _inline_math_ are quadruples _inline_math_ where _inline_math_ is a smooth paracompact orientable nonempty _inline_math_-manifold with finitely many connected components, _inline_math_ is a smooth time-orientable metric of signature _inline_math_ on _inline_math_, _inline_math_ and _inline_math_ are choices of orientation and %****␣1501.02682.tex␣Line␣600␣**** time-orientation respectively, 1 The orientation (resp., time-orientation) is conveniently represented as a choice of one of the connected components of the nowhere-zero smooth _inline_math_-forms (resp., _inline_math_-timelike _inline_math_-forms) on _inline_math_. so that the spacetime _inline_math_ is globally hyperbolic. That is, _inline_math_ has no closed causal curves and the intersections _inline_math_ of the causal future of _inline_math_ with the causal past of _inline_math_ is compact (including the possibility of being empty) for any pair of points _inline_math_. A morphism between two objects _inline_math_ and _inline_math_ of _inline_math_ is any smooth embedding _inline_math_ that is isometric, preserves the (time)orientation (i.e., _inline_math_, _inline_math_, _inline_math_) and has a causally convex image. If the image contains a Cauchy surface of _inline_math_, _inline_math_ will be described as a Cauchy morphism. \n",
      "----------------------------\n",
      "b'<dfndum>quantifies the density</dfndum>'\n",
      "article 1501_005/1501.02861/ordinal-embedding-v10-post-BEJ.xml 167\n",
      " Define _inline_math_, which quantifies the density of _inline_math_ in _inline_math_. Because _inline_math_ and _inline_math_ is dense in _inline_math_, we have _inline_math_ as _inline_math_. \n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# search for term containing some text and get the paragraphs (cleaned)\n",
    "results = argot.xpath(\".//dfndum[contains(text(),'quant')]\")\n",
    "with tarfile.open(prom_path) as tar_fobj:\n",
    "    for r in results:\n",
    "        print(etree.tostring(r))\n",
    "        parent = r.getparent()\n",
    "        para_index = int(parent.get('index'))\n",
    "        grand_parent = parent.getparent()\n",
    "        gparent_name = grand_parent.get('name')\n",
    "        print(grand_parent.tag, gparent_name, grand_parent.get('num') )\n",
    "        xml_fobj = tar_fobj.extractfile(gparent_name)\n",
    "        #art = etree.parse(xml_fobj.extractfile())\n",
    "        art = etree.parse(xml_fobj)\n",
    "        para_lst = art.findall('.//latexml:para', namespaces=ns)\n",
    "        print(px.recutext_xml(para_lst[para_index]))\n",
    "        print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<para xml:id=\"p6\" xmlns=\"http://dlmf.nist.gov/LaTeXML\">\n",
      "<p>Let \\( \\,G\\, \\) be the Lie group \\( \\,SU(1,1)\\, \\). Consider the holomorphic action of its universal complexification \\( \\,G^{\\mathbb{C}}=SL(2,{\\mathbb{C}})\\, \\)\n",
      "on \\( \\,{\\mathbb{P}}^{1}\\times{\\mathbb{P}}^{1}\\, \\) defined by</p>\n",
      "<equation labels=\"LABEL:ACTION\" xml:id=\"S0.E1\">\n",
      "<tags>\n",
      "<tag>(1)</tag>\n",
      "<tag role=\"refnum\">1</tag>\n",
      "</tags>\n",
      "$$g\\cdot([z_{1}:z_{2}],[w_{1}:w_{2}]):=(\\,g\\cdot[z_{1}:z_{2}],\\ \\overline{\\sigma%\n",
      "(g)}\\cdot[w_{1}:w_{2}]\\,)\\,,$$\n",
      "</equation>\n",
      "</para>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tex_math_tags(p_tag):\n",
    "    s = BeautifulSoup(p_tag, \"html.parser\")\n",
    "    for M in s.select('math'):\n",
    "        # tex == content-tex ?\n",
    "        tex = M['tex']\n",
    "        M.clear()\n",
    "        if M['mode'] == 'inline':\n",
    "            M.string = '\\\\( ' + M['tex'] + ' \\\\)'\n",
    "        else:\n",
    "            M.string = '$$' + M['tex'] + '$$'\n",
    "        M.unwrap()\n",
    "    return s\n",
    "tt = tex_math_tags(ite[0]['p_tag'])\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_inline_math_ hola adios _inline_math_'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = '_inline_math__hola_adios__inline_math_'\n",
    "sample = re.sub('_', ' ', sample)\n",
    "sample = re.sub(' inline math ', '_inline_math_', sample)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
