{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925cb2ce-3506-4f7f-9738-22a526901db4",
   "metadata": {},
   "source": [
    "# Token Classification with Hugging Face\n",
    "Based on the tutorial\n",
    "https://huggingface.co/docs/transformers/tasks/token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff65e479-c777-44d4-b49e-6de6faeb5c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "from transformers import (AutoTokenizer,\n",
    "                          DataCollatorForTokenClassification,\n",
    "                          create_optimizer,\n",
    "                          TFAutoModelForTokenClassification,\n",
    "                          pipeline,\n",
    "                         )\n",
    "\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "import evaluate\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import sys, os\n",
    "currentdir = os.path.abspath(os.path.curdir)\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "sys.path.insert(0,parentdir+'/embed') \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import train_ner as tn\n",
    "import ner\n",
    "import ner.llm_utils as llu\n",
    "\n",
    "from nltk.chunk import conlltags2tree, ChunkScore\n",
    "\n",
    "import toml\n",
    "\n",
    "seqeval = evaluate.load('seqeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "520ba6b3-54f2-40c6-a534-32b5ea64c3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the problematic article is: examples.xml\n",
      "The name of the problematic article is: coding.xml\n",
      "The name of the problematic article is: spaces-pushouts.xml\n",
      "The name of the problematic article is: guide.xml\n",
      "The name of the problematic article is: moduli.xml\n",
      "The name of the problematic article is: more-groupoids.xml\n",
      "The name of the problematic article is: chapters.xml\n",
      "The name of the problematic article is: sets.xml\n",
      "The name of the problematic article is: obsolete.xml\n",
      "The name of the problematic article is: examples-defos.xml\n",
      "The name of the problematic article is: spaces-more-cohomology.xml\n",
      "The name of the problematic article is: bibliography.xml\n",
      "The name of the problematic article is: fdl.xml\n",
      "The name of the problematic article is: limits.xml\n",
      "The name of the problematic article is: conventions.xml\n",
      "The name of the problematic article is: introduction.xml\n",
      "The name of the problematic article is: quot.xml\n",
      "The name of the problematic article is: desirables.xml\n"
     ]
    }
   ],
   "source": [
    "cfg = tn.gen_cfg()\n",
    "text_lst = tn.get_wiki_pm_stacks_data(cfg)\n",
    "sent_tok, trainer_params = tn.gen_sent_tokzer(text_lst, cfg)\n",
    "tokens_lst, ner_tags_lst, title_lst = ner.bio_tag.put_ner_tags(text_lst, sent_tok)\n",
    "def_lst = ner.bio_tag.put_pos_ner_tags(text_lst, sent_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55606240-ff0a-433d-968f-f1da8582c723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'title', 'pos'],\n",
       "        num_rows: 21147\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'title', 'pos'],\n",
       "        num_rows: 2611\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'title', 'pos'],\n",
       "        num_rows: 2350\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_lst = [[d[0][1] for d in tree_lst['ner']] for tree_lst in def_lst]\n",
    "data_dict = {\n",
    "    'id': list(range(len(tokens_lst))),\n",
    "    'tokens': tokens_lst,\n",
    "    'ner_tags': ner_tags_lst,\n",
    "    'title': title_lst,\n",
    "    'pos': pos_lst,\n",
    "}\n",
    "ds = Dataset.from_dict(data_dict)\n",
    "temp1_dd = ds.train_test_split(test_size=0.1, shuffle=True)\n",
    "temp2_dd = temp1_dd['train'].train_test_split(test_size=0.1, shuffle=True)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train': temp2_dd['train'],\n",
    "    'test': temp1_dd['test'],\n",
    "    'valid': temp2_dd['test'],\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10eac3e8-31d5-4fac-a676-d4d4a17b7b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c3b818be4247bf9f76ac8cbdf26323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbab432d9a80466ba46b8b2abb699467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932a73bd612b446491150edc46d425ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checkpoint = 'distilbert-base-cased'\n",
    "checkpoint = 'xlm-roberta-base'\n",
    "#checkpoint = 'bert-base-cased'\n",
    "#checkpoint = 'bert-large-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "label_list = ['O', 'B-defndum', 'I-defndum']\n",
    "\n",
    "##checkpoint = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, add_prefix_space=True)\n",
    "#model = TFAutoModelForTokenClassification.from_pretrained('/media/hd1/trained_models/ner_model/HFtransformers/ner_Jul-29_13-01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "feaf952e-071d-483f-b9e6-356d7c2f27bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8505dfa337c44471bd67329db13471c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368b4300e80a45e88fe037616b827197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c512c850fcb4f67a2978fa9f4ea7173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples['tokens'],\n",
    "                                truncation=True,\n",
    "                                is_split_into_words=True)\n",
    "    \n",
    "    labels=[]\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "        \n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "#tokenized_wnut = wnut.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_ds = ds.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a366cc30-49bc-4535-8ca2-b39f376b91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = [label_list[i] for i in example['ner_tags']]\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    \n",
    "    return {\n",
    "        'precision': results['overall_precision'],\n",
    "        'recall': results['overall_recall'],\n",
    "        'f1': results['overall_f1'],\n",
    "        'accuracy': results['overall_accuracy'],\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32ecfcf7-b931-48a9-8339-4fe8761bdd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "...     0: \"O\",\n",
    "...     1: \"B-DFNDUM\",\n",
    "...     2: \"I-DFNDUM\",\n",
    "... }\n",
    ">>> label2id = {\n",
    "...     \"O\": 0,\n",
    "...     \"B-DFNDUM\": 1,\n",
    "...     \"I-DFNDUM\": 2,\n",
    "... }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ff5cc5d-ddb6-44c5-b69a-5525c721f18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef56fee5b6140c3a5040e888704eb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaForTokenClassification.\n",
      "\n",
      "Some layers of TFXLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_train_epochs = 3\n",
    "num_train_steps = (len(tokenized_ds['train']) // batch_size * num_train_epochs)\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr = 2e-5,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    "    num_warmup_steps=0,\n",
    ")\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ac0c8c9-cb96-4888-9324-dce2cd34c871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['<s>', '</s>', '<unk>', '</s>', '<pad>', '<s>', '<mask>'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "456d2215-cbb6-40da-abe5-fcbf23c21659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_ds[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=4,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    tokenized_ds[\"valid\"],\n",
    "    shuffle=False,\n",
    "    batch_size=4,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = model.prepare_tf_dataset(\n",
    "    tokenized_ds[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=4,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61be65e3-4668-41cc-8790-43351681f444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4432f6-2081-4938-bb62-abf1d1007c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5286/5286 [==============================] - 847s 158ms/step - loss: 0.0964 - val_loss: 0.0792 - precision: 0.6679 - recall: 0.6239 - f1: 0.6452 - accuracy: 0.9720\n",
      "Epoch 2/3\n",
      "5286/5286 [==============================] - 832s 157ms/step - loss: 0.0728 - val_loss: 0.0792 - precision: 0.6679 - recall: 0.6239 - f1: 0.6452 - accuracy: 0.9720\n",
      "Epoch 3/3\n",
      " 472/5286 [=>............................] - ETA: 12:08 - loss: 0.0713"
     ]
    }
   ],
   "source": [
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)\n",
    "callbacks = [metric_callback,]\n",
    "model.fit(x=tf_train_set,\n",
    "          validation_data=tf_validation_set,\n",
    "          epochs=3,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7101efe0-0038-4338-a2d0-7741d47213b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Formally , a transition system is a pair ( S , - ) where S is a set of states and - is a set of state transitions ( i.e. , a subset of S x S ) . '\n",
      "The real title is:  transition system\n",
      "The pipeline result is:  [{'entity': 'B-DFNDUM', 'score': 0.9698083, 'index': 5, 'word': 'transition', 'start': 13, 'end': 23}, {'entity': 'I-DFNDUM', 'score': 0.9639087, 'index': 6, 'word': 'system', 'start': 24, 'end': 30}]\n",
      "[CLS] O\n",
      "Form O\n",
      "##ally O\n",
      ", O\n",
      "a O\n",
      "transition B-DFNDUM\n",
      "system I-DFNDUM\n",
      "is O\n",
      "a O\n",
      "pair O\n",
      "( O\n",
      "S O\n",
      ", O\n",
      "- O\n",
      ") O\n",
      "where O\n",
      "S O\n",
      "is O\n",
      "a O\n",
      "set O\n",
      "of O\n",
      "states O\n",
      "and O\n",
      "- O\n",
      "is O\n",
      "a O\n",
      "set O\n",
      "of O\n",
      "state O\n",
      "transitions O\n",
      "( O\n",
      "i O\n",
      ". O\n",
      "e O\n",
      ". O\n",
      ", O\n",
      "a O\n",
      "subset O\n",
      "of O\n",
      "S O\n",
      "x O\n",
      "S O\n",
      ") O\n",
      ". O\n",
      "[SEP] O\n",
      "[{'entity': 'DFNDUM', 'score': 0.48646090587135404, 'word': 'transition system', 'start': 13, 'end': 30}]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"We define a Banach space as a complete vector normed space.\"\"\"\n",
    "text = ''\n",
    "j = 19\n",
    "for t in ds['test'][j]['tokens']:\n",
    "    text += t + ' '\n",
    "print(f'{text=}')\n",
    "print(f'The real title is: ', ' '.join([ds['test'][j]['tokens'][k]\n",
    "                         for k, n in enumerate(ds['test'][j]['ner_tags']) if n != 0]))\n",
    "classifier = pipeline('ner', model=model, tokenizer=tokenizer)\n",
    "print('The pipeline result is: ', classifier(text))\n",
    "\n",
    "inputs = tokenizer(text, return_tensors='tf')\n",
    "logits = model(**inputs).logits\n",
    "predicted_ids = tf.math.argmax(logits, axis=-1)\n",
    "predicted_token_class = [model.config.id2label[t] for t in predicted_ids[0].numpy().tolist()]\n",
    "\n",
    "for i in range(len(predicted_token_class)):\n",
    "    print(inputs.tokens()[i], predicted_token_class[i])\n",
    "\n",
    "tt = tokenizer(ds['test'][j]['tokens'], return_tensors='tf', is_split_into_words=True)\n",
    "logits = model(**tt).logits\n",
    "\n",
    "# Grouping entities\n",
    "predicted_ids = tf.math.argmax(logits, axis=-1)[0]\n",
    "predictions = predicted_ids.numpy().tolist()\n",
    "results = []\n",
    "inputs_with_offsets = tokenizer(text, return_offsets_mapping=True)\n",
    "tokens = inputs_with_offsets.tokens()\n",
    "offsets = inputs_with_offsets['offset_mapping']\n",
    "\n",
    "probs = tf.math.softmax(logits, axis=-1)[0]\n",
    "probs = probs.numpy().tolist()\n",
    "\n",
    "#start, end = inputs.word_to_chars(10)\n",
    "end = 0\n",
    "\n",
    "idx = 0\n",
    "while idx < len(predictions):\n",
    "    pred = predictions[idx]\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != 'O':\n",
    "        label = label[2:]\n",
    "        start, end = offsets[idx] # 2nd output is the end of word\n",
    "        #idx += 1\n",
    "        \n",
    "        # Grab all tokens labeled with an I-label\n",
    "        all_scores = []\n",
    "        while (\n",
    "            idx < len(predictions)\n",
    "            and model.config.id2label[predictions[idx]][2:] == label\n",
    "               ):\n",
    "            all_scores.append(probs[idx][pred])\n",
    "            _, end = offsets[idx]\n",
    "            idx += 1\n",
    "            \n",
    "        score = np.mean(all_scores).item()\n",
    "        word = text[start:end]\n",
    "        results.append(\n",
    "            {'entity': label, \n",
    "             'score': score,\n",
    "             'word': word,\n",
    "            'start': start,\n",
    "            'end': end,}\n",
    "        )\n",
    "    idx += 1\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84cff041-ec3a-445d-acde-527829b11de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  99.5%%\n",
      "    Precision:     94.2%%\n",
      "    Recall:        91.6%%\n",
      "    F-Measure:     92.9%%\n"
     ]
    }
   ],
   "source": [
    "#j=780\n",
    "chunkscore = ChunkScore()\n",
    "\n",
    "spec_toks = list(tokenizer.special_tokens_map.values())\n",
    "spec_toks.remove('[UNK]')\n",
    "\n",
    "\n",
    "dif_len_lst = []\n",
    "for j in range(len(ds['test'])):\n",
    "    tt = tokenizer(ds['test'][j]['tokens'], return_tensors='tf', is_split_into_words=True)\n",
    "    logits = model(**tt).logits\n",
    "\n",
    "    # Grouping entities\n",
    "    predicted_ids = tf.math.argmax(logits, axis=-1)[0]\n",
    "    predictions = predicted_ids.numpy().tolist()\n",
    "    pp = [model.config.id2label[t] for t in predictions]\n",
    "\n",
    "    wl, il = llu.get_words_back(tt.tokens(),\n",
    "                          preds=pp, special_tokens=spec_toks)\n",
    "    try:\n",
    "        wl, il = llu.join_by_example(wl, ds['test'][j]['tokens'], preds=il)\n",
    "    except AssertionError:\n",
    "        print(f'Index {j=} caused the error')\n",
    "\n",
    "    tree_pred = conlltags2tree([(tok, 'Upa', pred) for tok, pred in zip(wl, il)])\n",
    "\n",
    "    jdict = ds['test'][j]\n",
    "    bio_tagged = tn.tf_bio_tagger(jdict['ner_tags'])\n",
    "    tree_gold = conlltags2tree([(jdict['tokens'][i], \n",
    "                                 'Upa', \n",
    "                                 bio_tagged[i])\n",
    "                                for i in range(len(jdict['tokens']))])\n",
    "\n",
    "    chunkscore.score(tree_pred, tree_gold)\n",
    "    \n",
    "    if len(wl) != len(jdict['tokens']):\n",
    "        dif_len_lst.append(j)\n",
    "#for i in range(len(il)):\n",
    "    #print(f\"{wl[i]:<15} {il[i]:<10} {jdict['tokens'][i]:<15} {bio_tagged[i]}\")\n",
    "    #print(f\"{wl[i]:<20} {il[i]:<10}\") \n",
    "print(chunkscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02ad6a3-f2c4-41ee-b21f-001189e35827",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(ds['test'])):\n",
    "    if ['There', 'are', 'two', 'approaches'] == ds['test'][j]['tokens'][:4]:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "713da924-719a-4ab4-89df-415074d0b9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Given           O          Given           O\n",
      "1  two             O          two             O\n",
      "2  topological     O          topological     O\n",
      "3  spaces          O          spaces          O\n",
      "4  _inline_math_   O          _inline_math_   O\n",
      "5  and             O          and             O\n",
      "6  _inline_math_   O          _inline_math_   O\n",
      "7  ,               O          ,               O\n",
      "8  their           O          their           O\n",
      "9  topological     B-DFNDUM   topological     B-DFNDUM\n",
      "10  sum             I-DFNDUM   sum             I-DFNDUM\n",
      "11  is              O          is              O\n",
      "12  defined         O          defined         O\n",
      "13  to              O          to              O\n",
      "14  be              O          be              O\n",
      "15  the             O          the             O\n",
      "16  set             O          set             O\n",
      "17  _inline_math_   O          _inline_math_   O\n",
      "18  (               O          (               O\n",
      "19  see             O          see             O\n",
      "20  the             O          the             O\n",
      "21  entry           O          entry           O\n",
      "22  disjoint        O          disjoint        O\n",
      "23  union           O          union           O\n",
      "24  )               O          )               O\n",
      "25  equipped        O          equipped        O\n",
      "26  with            O          with            O\n",
      "27  the             O          the             O\n",
      "28  finest          O          finest          O\n",
      "29  topology        O          topology        O\n",
      "30  such            O          such            O\n",
      "31  that            O          that            O\n",
      "32  the             O          the             O\n",
      "33  inclusion       O          inclusion       O\n",
      "34  maps            O          maps            O\n",
      "35  from            O          from            O\n",
      "36  _inline_math_   O          _inline_math_   O\n",
      "37  and             O          and             O\n",
      "38  _inline_math_   O          _inline_math_   O\n",
      "39  into            O          into            O\n",
      "40  _inline_math_   O          _inline_math_   O\n",
      "41  are             O          are             O\n",
      "42  continuous      O          continuous      O\n",
      "43  .               O          .               O\n"
     ]
    }
   ],
   "source": [
    "j=142\n",
    "tt = tokenizer(ds['test'][j]['tokens'], return_tensors='tf', is_split_into_words=True)\n",
    "logits = model(**tt).logits\n",
    "\n",
    "# Grouping entities\n",
    "predicted_ids = tf.math.argmax(logits, axis=-1)[0]\n",
    "predictions = predicted_ids.numpy().tolist()\n",
    "pp = [model.config.id2label[t] for t in predictions]\n",
    "\n",
    "wl, il = ner.llm_utils.get_words_back(tt.tokens(),\n",
    "                      preds=pp, special_tokens=tokenizer.special_tokens_map.values())\n",
    "#wl, il = ner.llm_utils.join_math_tokens(wl, il)\n",
    "\n",
    "tree_pred = conlltags2tree([(tok, 'Upa', pred) for tok, pred in zip(wl, il)])\n",
    "\n",
    "jdict = ds['test'][j]\n",
    "bio_tagged = tn.tf_bio_tagger(jdict['ner_tags'])\n",
    "tree_gold = conlltags2tree([(jdict['tokens'][i], \n",
    "                             'Upa', \n",
    "                             bio_tagged[i])\n",
    "                            for i in range(len(jdict['tokens']))])\n",
    "\n",
    "#for i in range(len(il)):\n",
    "#    print(f\"{wl[i]:<15} {il[i]:<10} {jdict['tokens'][i]:<15} {bio_tagged[i]}\")\n",
    "    #print(f\"{wl[i]:<20} {il[i]:<10}\") \n",
    "\n",
    "joined_toks, joined_preds = llu.join_by_example(wl, jdict['tokens'], preds=il)\n",
    "short_gold = ['1', '\\\\in', 'c', 'a', 'be', 'fin']\n",
    "short_pred = ['1', '\\\\', 'in', 'c', 'a', 'b', 'e', 'fin']\n",
    "#joined_preds = join_by_example(short_pred, short_gold)\n",
    "for i in range(len(joined_toks)):\n",
    "    print(f\"{i}  {joined_toks[i]:<15} {joined_preds[i]:<10} {jdict['tokens'][i]:<15} {bio_tagged[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb6b592b-c543-492e-b39a-92385ed3545f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\\\in'.startswith('\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c31d44-1eed-4081-8f92-bd6d7a052927",
   "metadata": {},
   "source": [
    "## Previous Results\n",
    "**bert-base-cased**\n",
    "```text\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  97.7%%\n",
    "    Precision:     74.3%%\n",
    "    Recall:        69.9%%\n",
    "    F-Measure:     72.0%%\n",
    "```\n",
    "\n",
    "```text\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  97.9%%\n",
    "    Precision:     77.9%%\n",
    "    Recall:        72.3%%\n",
    "    F-Measure:     75.0%%\n",
    "```\n",
    "\n",
    "```text\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  98.2%%\n",
    "    Precision:     80.1%%\n",
    "    Recall:        76.7%%\n",
    "    F-Measure:     78.4%%\n",
    "```\n",
    "\n",
    "**bert-large-cased** (Bridges)\n",
    "\n",
    "5 Epochs\n",
    "```text\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  98.3%%\n",
    "    Precision:     82.7%%\n",
    "    Recall:        79.4%%\n",
    "    F-Measure:     81.0%%\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7154c2-eb82-4448-a905-d167dbce6292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
