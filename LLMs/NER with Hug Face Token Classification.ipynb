{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925cb2ce-3506-4f7f-9738-22a526901db4",
   "metadata": {},
   "source": [
    "# Token Classification with Hugging Face\n",
    "Based on the tutorial\n",
    "https://huggingface.co/docs/transformers/tasks/token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff65e479-c777-44d4-b49e-6de6faeb5c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 10:37:08.548327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-19 10:37:08.553180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-19 10:37:08.553325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "from transformers import (AutoTokenizer,\n",
    "                          DataCollatorForTokenClassification,\n",
    "                          create_optimizer,\n",
    "                          TFAutoModelForTokenClassification,\n",
    "                          pipeline,\n",
    "                         )\n",
    "\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "import evaluate\n",
    "from nltk import word_tokenize\n",
    "from lxml import etree\n",
    "\n",
    "import sys, os\n",
    "currentdir = os.path.abspath(os.path.curdir)\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "sys.path.insert(0,parentdir+'/embed') \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import train_ner as tn\n",
    "import ner\n",
    "import ner.llm_utils as llu\n",
    "import embed.inference_ner as iner\n",
    "\n",
    "from nltk.chunk import conlltags2tree, ChunkScore\n",
    "\n",
    "import toml\n",
    "\n",
    "seqeval = evaluate.load('seqeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520ba6b3-54f2-40c6-a534-32b5ea64c3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the problematic article is: examples.xml\n",
      "The name of the problematic article is: coding.xml\n",
      "The name of the problematic article is: spaces-pushouts.xml\n",
      "The name of the problematic article is: guide.xml\n",
      "The name of the problematic article is: moduli.xml\n",
      "The name of the problematic article is: more-groupoids.xml\n",
      "The name of the problematic article is: chapters.xml\n",
      "The name of the problematic article is: sets.xml\n",
      "The name of the problematic article is: obsolete.xml\n",
      "The name of the problematic article is: examples-defos.xml\n",
      "The name of the problematic article is: spaces-more-cohomology.xml\n",
      "The name of the problematic article is: bibliography.xml\n",
      "The name of the problematic article is: fdl.xml\n",
      "The name of the problematic article is: limits.xml\n",
      "The name of the problematic article is: conventions.xml\n",
      "The name of the problematic article is: introduction.xml\n",
      "The name of the problematic article is: quot.xml\n",
      "The name of the problematic article is: desirables.xml\n"
     ]
    }
   ],
   "source": [
    "cfg = tn.gen_cfg()\n",
    "text_lst = tn.get_wiki_pm_stacks_data(cfg)\n",
    "sent_tok, trainer_params = tn.gen_sent_tokzer(text_lst, cfg)\n",
    "tokens_lst, ner_tags_lst, title_lst = ner.bio_tag.put_ner_tags(text_lst, sent_tok)\n",
    "def_lst = ner.bio_tag.put_pos_ner_tags(text_lst, sent_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55606240-ff0a-433d-968f-f1da8582c723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'title', 'pos'],\n",
       "        num_rows: 21142\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'title', 'pos'],\n",
       "        num_rows: 2611\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'title', 'pos'],\n",
       "        num_rows: 2350\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_lst = [[d[0][1] for d in tree_lst['ner']] for tree_lst in def_lst]\n",
    "data_dict = {\n",
    "    'id': list(range(len(tokens_lst))),\n",
    "    'tokens': tokens_lst,\n",
    "    'ner_tags': ner_tags_lst,\n",
    "    'title': title_lst,\n",
    "    'pos': pos_lst,\n",
    "}\n",
    "ds = Dataset.from_dict(data_dict)\n",
    "temp1_dd = ds.train_test_split(test_size=0.1, shuffle=True)\n",
    "temp2_dd = temp1_dd['train'].train_test_split(test_size=0.1, shuffle=True)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train': temp2_dd['train'],\n",
    "    'test': temp1_dd['test'],\n",
    "    'valid': temp2_dd['test'],\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10eac3e8-31d5-4fac-a676-d4d4a17b7b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at /media/hd1/trained_models/ner_model/HFtransformers/ner-2023-08-01_1627/trainer/trans_HF_ner/ner_Aug-01_16-28/ were not used when initializing TFBertForTokenClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at /media/hd1/trained_models/ner_model/HFtransformers/ner-2023-08-01_1627/trainer/trans_HF_ner/ner_Aug-01_16-28/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#checkpoint = 'distilbert-base-cased'\n",
    "#checkpoint = 'xlm-roberta-base'\n",
    "checkpoint = 'bert-base-cased'\n",
    "#checkpoint = 'bert-large-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "label_list = ['O', 'B-defndum', 'I-defndum']\n",
    "\n",
    "##checkpoint = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, add_prefix_space=True)\n",
    "model_path = '/media/hd1/trained_models/ner_model/HFtransformers/ner-2023-08-01_1627/trainer/trans_HF_ner/ner_Aug-01_16-28/'\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feaf952e-071d-483f-b9e6-356d7c2f27bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c9a1a494d84ce4a86b43ed27111ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2406efc0ce054f818c18d175fe58277e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539172ff9db6441093c8f37074987dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples['tokens'],\n",
    "                                truncation=True,\n",
    "                                is_split_into_words=True)\n",
    "    \n",
    "    labels=[]\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "        \n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "#tokenized_wnut = wnut.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_ds = ds.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a366cc30-49bc-4535-8ca2-b39f376b91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = [label_list[i] for i in example['ner_tags']]\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    \n",
    "    return {\n",
    "        'precision': results['overall_precision'],\n",
    "        'recall': results['overall_recall'],\n",
    "        'f1': results['overall_f1'],\n",
    "        'accuracy': results['overall_accuracy'],\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ecfcf7-b931-48a9-8339-4fe8761bdd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "...     0: \"O\",\n",
    "...     1: \"B-DFNDUM\",\n",
    "...     2: \"I-DFNDUM\",\n",
    "... }\n",
    ">>> label2id = {\n",
    "...     \"O\": 0,\n",
    "...     \"B-DFNDUM\": 1,\n",
    "...     \"I-DFNDUM\": 2,\n",
    "... }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ff5cc5d-ddb6-44c5-b69a-5525c721f18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_train_epochs = 3\n",
    "num_train_steps = (len(tokenized_ds['train']) // batch_size * num_train_epochs)\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr = 2e-5,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    "    num_warmup_steps=0,\n",
    ")\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac0c8c9-cb96-4888-9324-dce2cd34c871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "456d2215-cbb6-40da-abe5-fcbf23c21659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/luis/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:717: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_ds[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=1,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    tokenized_ds[\"valid\"],\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = model.prepare_tf_dataset(\n",
    "    tokenized_ds[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61be65e3-4668-41cc-8790-43351681f444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce4432f6-2081-4938-bb62-abf1d1007c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "21154/21154 [==============================] - 2868s 135ms/step - loss: 0.0787 - val_loss: 0.0856 - precision: 0.6460 - recall: 0.6717 - f1: 0.6586 - accuracy: 0.9738\n",
      "Epoch 2/3\n",
      "21154/21154 [==============================] - 2855s 135ms/step - loss: 0.0749 - val_loss: 0.0856 - precision: 0.6460 - recall: 0.6717 - f1: 0.6586 - accuracy: 0.9738\n",
      "Epoch 3/3\n",
      "21154/21154 [==============================] - 2858s 135ms/step - loss: 0.0747 - val_loss: 0.0856 - precision: 0.6460 - recall: 0.6717 - f1: 0.6586 - accuracy: 0.9738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d0c2b1480>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)\n",
    "callbacks = [metric_callback,]\n",
    "model.fit(x=tf_train_set,\n",
    "          validation_data=tf_validation_set,\n",
    "          epochs=3,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7101efe0-0038-4338-a2d0-7741d47213b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='We define a Banach space as a complete vector normed space.'\n",
      "The pipeline result is:  [{'entity': 'B-DFNDUM', 'score': 0.99795747, 'index': 4, 'word': 'Ban', 'start': 12, 'end': 15}, {'entity': 'I-DFNDUM', 'score': 0.87701976, 'index': 5, 'word': '##ach', 'start': 15, 'end': 18}, {'entity': 'I-DFNDUM', 'score': 0.9935475, 'index': 6, 'word': 'space', 'start': 19, 'end': 24}]\n",
      "[CLS] O\n",
      "We O\n",
      "define O\n",
      "a O\n",
      "Ban B-DFNDUM\n",
      "##ach I-DFNDUM\n",
      "space I-DFNDUM\n",
      "as O\n",
      "a O\n",
      "complete O\n",
      "vector O\n",
      "norm O\n",
      "##ed O\n",
      "space O\n",
      ". O\n",
      "[SEP] O\n",
      "logits=<tf.Tensor: shape=(1, 16, 3), dtype=float32, numpy=\n",
      "array([[[ 3.030289  , -2.0339897 , -2.0566025 ],\n",
      "        [ 7.8431334 , -4.7557993 , -4.332306  ],\n",
      "        [ 7.9283433 , -4.4622803 , -4.4607487 ],\n",
      "        [ 7.735637  , -4.489064  , -3.966631  ],\n",
      "        [-0.56327933,  5.646585  , -4.5539656 ],\n",
      "        [-2.3025973 ,  0.08733091,  2.1395137 ],\n",
      "        [-0.1091496 , -5.2520733 ,  4.9334927 ],\n",
      "        [ 7.901957  , -4.716515  , -4.1931643 ],\n",
      "        [ 7.9019723 , -4.7961826 , -4.1535664 ],\n",
      "        [ 7.08629   , -3.0740774 , -4.472606  ],\n",
      "        [ 6.874388  , -3.749901  , -3.6858654 ],\n",
      "        [ 7.2444654 , -5.137642  , -2.73001   ],\n",
      "        [ 7.477514  , -5.177245  , -3.2656243 ],\n",
      "        [ 7.408746  , -5.2392225 , -3.0462787 ],\n",
      "        [ 7.9188957 , -4.8342133 , -4.2293916 ],\n",
      "        [ 3.42609   , -1.9353966 , -1.8082595 ]]], dtype=float32)>\n",
      "[{'entity': 'DFNDUM', 'score': 0.37021726317470893, 'word': 'Banach space', 'start': 12, 'end': 24}]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"We define a Banach space as a complete vector normed space.\"\"\"\n",
    "#text = ''\n",
    "#j = 19\n",
    "#for t in ds['test'][j]['tokens']:\n",
    "#    text += t + ' '\n",
    "print(f'{text=}')\n",
    "#print(f'The real title is: ', ' '.join([ds['test'][j]['tokens'][k]\n",
    "#                         for k, n in enumerate(ds['test'][j]['ner_tags']) if n != 0]))\n",
    "classifier = pipeline('ner', model=model, tokenizer=tokenizer)\n",
    "print('The pipeline result is: ', classifier(text))\n",
    "\n",
    "inputs = tokenizer(text, return_tensors='tf')\n",
    "logits = model(**inputs).logits\n",
    "predicted_ids = tf.math.argmax(logits, axis=-1)\n",
    "predicted_token_class = [model.config.id2label[t] for t in predicted_ids[0].numpy().tolist()]\n",
    "\n",
    "for i in range(len(predicted_token_class)):\n",
    "    print(inputs.tokens()[i], predicted_token_class[i])\n",
    "\n",
    "#tt = tokenizer(ds['test'][j]['tokens'], return_tensors='tf', is_split_into_words=True)\n",
    "tt = tokenizer(text, return_tensors='tf', is_split_into_words=False)\n",
    "logits = model(**tt).logits\n",
    "print(f\"{logits=}\")\n",
    "\n",
    "# Grouping entities\n",
    "predicted_ids = tf.math.argmax(logits, axis=-1)[0]\n",
    "predictions = predicted_ids.numpy().tolist()\n",
    "results = []\n",
    "inputs_with_offsets = tokenizer(text, return_offsets_mapping=True)\n",
    "tokens = inputs_with_offsets.tokens()\n",
    "offsets = inputs_with_offsets['offset_mapping']\n",
    "\n",
    "probs = tf.math.softmax(logits, axis=-1)[0]\n",
    "probs = probs.numpy().tolist()\n",
    "\n",
    "#start, end = inputs.word_to_chars(10)\n",
    "end = 0\n",
    "\n",
    "idx = 0\n",
    "while idx < len(predictions):\n",
    "    pred = predictions[idx]\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != 'O':\n",
    "        label = label[2:]\n",
    "        start, end = offsets[idx] # 2nd output is the end of word\n",
    "        #idx += 1\n",
    "        \n",
    "        # Grab all tokens labeled with an I-label\n",
    "        all_scores = []\n",
    "        while (\n",
    "            idx < len(predictions)\n",
    "            and model.config.id2label[predictions[idx]][2:] == label\n",
    "               ):\n",
    "            all_scores.append(probs[idx][pred])\n",
    "            _, end = offsets[idx]\n",
    "            idx += 1\n",
    "            \n",
    "        score = np.mean(all_scores).item()\n",
    "        word = text[start:end]\n",
    "        results.append(\n",
    "            {'entity': label, \n",
    "             'score': score,\n",
    "             'word': word,\n",
    "            'start': start,\n",
    "            'end': end,}\n",
    "        )\n",
    "    idx += 1\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89271ae7-7009-4aab-b827-ccc4994b75a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[CLS]',                      'O'),\n",
      "('A',                      'O'),\n",
      "('mon',                      'O'),\n",
      "('##oid',                      'O'),\n",
      "('##al',                      'O'),\n",
      "('category',                      'O'),\n",
      "('is',                      'O'),\n",
      "('symmetric',                      'B-DFNDUM'),\n",
      "('mon',                      'I-DFNDUM'),\n",
      "('##oid',                      'I-DFNDUM'),\n",
      "('##al',                      'I-DFNDUM'),\n",
      "('if',                      'O'),\n",
      "('it',                      'O'),\n",
      "('has',                      'O'),\n",
      "('the',                      'O'),\n",
      "('special',                      'O'),\n",
      "('arrow',                      'O'),\n",
      "('_',                      'O'),\n",
      "('display',                      'O'),\n",
      "('_',                      'O'),\n",
      "('math',                      'O'),\n",
      "('_',                      'O'),\n",
      "('for',                      'O'),\n",
      "('every',                      'O'),\n",
      "('pair',                      'O'),\n",
      "('_',                      'O'),\n",
      "('in',                      'O'),\n",
      "('##line',                      'O'),\n",
      "('_',                      'O'),\n",
      "('math',                      'O'),\n",
      "('_',                      'O'),\n",
      "('of',                      'O'),\n",
      "('its',                      'O'),\n",
      "('objects',                      'O'),\n",
      "(',',                      'O'),\n",
      "('and',                      'O'),\n",
      "('if',                      'O'),\n",
      "('the',                      'O'),\n",
      "('following',                      'O'),\n",
      "('equations',                      'O'),\n",
      "('hold',                      'O'),\n",
      "('c',                      'O'),\n",
      "('-',                      'O'),\n",
      "('equations',                      'O'),\n",
      "('(',                      'O'),\n",
      "('c',                      'O'),\n",
      "(')',                      'O'),\n",
      "('For',                      'O'),\n",
      "('_',                      'O'),\n",
      "('in',                      'O'),\n",
      "('##line',                      'O'),\n",
      "('_',                      'O'),\n",
      "('math',                      'O'),\n",
      "('_',                      'O'),\n",
      "('and',                      'O'),\n",
      "('_',                      'O'),\n",
      "('in',                      'O'),\n",
      "('##line',                      'O'),\n",
      "('_',                      'O'),\n",
      "('math',                      'O'),\n",
      "('_',                      'O'),\n",
      "(',',                      'O'),\n",
      "('_',                      'O'),\n",
      "('in',                      'O'),\n",
      "('##line',                      'O'),\n",
      "('_',                      'O'),\n",
      "('math',                      'O'),\n",
      "('_',                      'O'),\n",
      "('(',                      'O'),\n",
      "('cc',                      'O'),\n",
      "(')',                      'O'),\n",
      "('_',                      'O'),\n",
      "('in',                      'O'),\n",
      "('##line',                      'O'),\n",
      "('_',                      'O'),\n",
      "('math',                      'O'),\n",
      "('_',                      'O'),\n",
      "('(',                      'O'),\n",
      "('_',                      'O'),\n",
      "('in',                      'O'),\n",
      "('##line',                      'O'),\n",
      "('_',                      'O'),\n",
      "('math',                      'O'),\n",
      "('_',                      'O'),\n",
      "('_',                      'O'),\n",
      "('in',                      'O'),\n",
      "('##line',                      'O'),\n",
      "('_',                      'O'),\n",
      "('math',                      'O'),\n",
      "('_',                      'O'),\n",
      "('c',                      'O'),\n",
      "(')',                      'O'),\n",
      "('_',                      'O'),\n",
      "('in',                      'O'),\n",
      "('##line',                      'O'),\n",
      "('_',                      'O'),\n",
      "('math',                      'O'),\n",
      "('_',                      'O'),\n",
      "('(',                      'O'),\n",
      "('b',                      'O'),\n",
      "('##c',                      'O'),\n",
      "('##6',                      'O'),\n",
      "(')',                      'O'),\n",
      "('_',                      'O'),\n",
      "('in',                      'O'),\n",
      "('##line',                      'O'),\n",
      "('_',                      'O'),\n",
      "('math',                      'O'),\n",
      "('_',                      'O'),\n",
      "('[SEP]',                      'O'),\n"
     ]
    }
   ],
   "source": [
    "xml_path = '/media/hd1/glossary/inference_class_all/math00/0006_001.xml.gz'\n",
    "model_dir = '/media/hd1/trained_models/ner_model/lstm_ner/ner_Sep-29_15-37/exp_041/'\n",
    "sent_tok = iner.read_sent_tok(os.path.join(model_dir, 'punkt_params.pickle'))\n",
    "pars = etree.XMLParser(recover=True)                                           \n",
    "xml_tree = etree.parse(xml_path, parser=pars)                                  \n",
    "root = xml_tree.getroot()\n",
    "Defs = root.findall('.//definition')   \n",
    "\n",
    "#sent_lst = iner.str_tok_pos_tags(Defs[12].find('stmnt').text, sent_tok )\n",
    "sent_lst = sent_tok.tokenize(Defs[70].find('stmnt').text)\n",
    "\n",
    "\n",
    "empty = ''\n",
    "\n",
    "tt = tokenizer(sent_lst, return_tensors='tf', is_split_into_words=False, padding=True, truncation=True)\n",
    "logits = model(**tt)['logits']\n",
    "predicted_ids = tf.math.argmax(logits, axis=-1)\n",
    "predictions = predicted_ids.numpy().tolist()\n",
    "for j,p in enumerate(predictions):\n",
    "    label_lst = [model.config.id2label[t] for t in p]\n",
    "    for k,lab in enumerate(label_lst):\n",
    "        print(f\"('{tt.tokens(j)[k]}', {empty:>20} '{lab}'),\")\n",
    "#join1 = llu.get_words_back(tt.tokens(1))[0]\n",
    "#llu.join_math_tokens(join1)[0]\n",
    "#join1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84cff041-ec3a-445d-acde-527829b11de2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  99.5%%\n",
      "    Precision:     94.8%%\n",
      "    Recall:        91.6%%\n",
      "    F-Measure:     93.2%%\n"
     ]
    }
   ],
   "source": [
    "#j=780\n",
    "chunkscore = ChunkScore()\n",
    "\n",
    "spec_toks = list(tokenizer.special_tokens_map.values())\n",
    "spec_toks.remove('[UNK]')\n",
    "#spec_toks.remove('<unk>')\n",
    "\n",
    "\n",
    "dif_len_lst = []\n",
    "for j in range(len(ds['test'])):\n",
    "    tt = tokenizer(ds['test'][j]['tokens'], return_tensors='tf', is_split_into_words=True)\n",
    "    logits = model(**tt).logits\n",
    "\n",
    "    # Grouping entities\n",
    "    predicted_ids = tf.math.argmax(logits, axis=-1)[0]\n",
    "    predictions = predicted_ids.numpy().tolist()\n",
    "    pp = [model.config.id2label[t] for t in predictions]\n",
    "\n",
    "    wl, il = llu.get_words_back(tt.tokens(),\n",
    "                          preds=pp, special_tokens=spec_toks)\n",
    "    try:\n",
    "        wl, il = llu.join_by_example(wl, ds['test'][j]['tokens'], preds=il)\n",
    "    except AssertionError:\n",
    "        print(f'Index {j=} caused the error')\n",
    "\n",
    "    tree_pred = conlltags2tree([(tok, 'Upa', pred) for tok, pred in zip(wl, il)])\n",
    "\n",
    "    jdict = ds['test'][j]\n",
    "    bio_tagged = tn.tf_bio_tagger(jdict['ner_tags'])\n",
    "    tree_gold = conlltags2tree([(jdict['tokens'][i], \n",
    "                                 'Upa', \n",
    "                                 bio_tagged[i])\n",
    "                                for i in range(len(jdict['tokens']))])\n",
    "\n",
    "    chunkscore.score(tree_pred, tree_gold)\n",
    "    \n",
    "    if len(wl) != len(jdict['tokens']):\n",
    "        dif_len_lst.append(j)\n",
    "#for i in range(len(il)):\n",
    "    #print(f\"{wl[i]:<15} {il[i]:<10} {jdict['tokens'][i]:<15} {bio_tagged[i]}\")\n",
    "    #print(f\"{wl[i]:<20} {il[i]:<10}\") \n",
    "print(chunkscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb888d9-7414-4b1f-bb2c-6fd6ef1c80cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ad6a3-f2c4-41ee-b21f-001189e35827",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(ds['test'])):\n",
    "    if ['There', 'are', 'two', 'approaches'] == ds['test'][j]['tokens'][:4]:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713da924-719a-4ab4-89df-415074d0b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=142\n",
    "tt = tokenizer(ds['test'][j]['tokens'], return_tensors='tf', is_split_into_words=True)\n",
    "logits = model(**tt).logits\n",
    "\n",
    "# Grouping entities\n",
    "predicted_ids = tf.math.argmax(logits, axis=-1)[0]\n",
    "predictions = predicted_ids.numpy().tolist()\n",
    "pp = [model.config.id2label[t] for t in predictions]\n",
    "\n",
    "wl, il = ner.llm_utils.get_words_back(tt.tokens(),\n",
    "                      preds=pp, special_tokens=tokenizer.special_tokens_map.values())\n",
    "#wl, il = ner.llm_utils.join_math_tokens(wl, il)\n",
    "\n",
    "tree_pred = conlltags2tree([(tok, 'Upa', pred) for tok, pred in zip(wl, il)])\n",
    "\n",
    "jdict = ds['test'][j]\n",
    "bio_tagged = tn.tf_bio_tagger(jdict['ner_tags'])\n",
    "tree_gold = conlltags2tree([(jdict['tokens'][i], \n",
    "                             'Upa', \n",
    "                             bio_tagged[i])\n",
    "                            for i in range(len(jdict['tokens']))])\n",
    "\n",
    "#for i in range(len(il)):\n",
    "#    print(f\"{wl[i]:<15} {il[i]:<10} {jdict['tokens'][i]:<15} {bio_tagged[i]}\")\n",
    "    #print(f\"{wl[i]:<20} {il[i]:<10}\") \n",
    "\n",
    "joined_toks, joined_preds = llu.join_by_example(wl, jdict['tokens'], preds=il)\n",
    "short_gold = ['1', '\\\\in', 'c', 'a', 'be', 'fin']\n",
    "short_pred = ['1', '\\\\', 'in', 'c', 'a', 'b', 'e', 'fin']\n",
    "#joined_preds = join_by_example(short_pred, short_gold)\n",
    "for i in range(len(joined_toks)):\n",
    "    print(f\"{i}  {joined_toks[i]:<15} {joined_preds[i]:<10} {jdict['tokens'][i]:<15} {bio_tagged[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c31d44-1eed-4081-8f92-bd6d7a052927",
   "metadata": {},
   "source": [
    "## Previous Results\n",
    "**bert-base-cased**\n",
    "```text\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  97.7%%\n",
    "    Precision:     74.3%%\n",
    "    Recall:        69.9%%\n",
    "    F-Measure:     72.0%%\n",
    "```\n",
    "\n",
    "```text\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  97.9%%\n",
    "    Precision:     77.9%%\n",
    "    Recall:        72.3%%\n",
    "    F-Measure:     75.0%%\n",
    "```\n",
    "\n",
    "```text\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  98.2%%\n",
    "    Precision:     80.1%%\n",
    "    Recall:        76.7%%\n",
    "    F-Measure:     78.4%%\n",
    "```\n",
    "\n",
    "**bert-large-cased** (Bridges)\n",
    "\n",
    "5 Epochs\n",
    "```text\n",
    "ChunkParse score:\n",
    "    IOB Accuracy:  98.3%%\n",
    "    Precision:     82.7%%\n",
    "    Recall:        79.4%%\n",
    "    F-Measure:     81.0%%\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7154c2-eb82-4448-a905-d167dbce6292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
