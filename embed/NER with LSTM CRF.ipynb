{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "NER",
     "Tensorflow2.0"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional,\\\n",
    "                      GRU, Dropout,GlobalAveragePooling1D, Conv1D, TimeDistributed,\\\n",
    "                      Input, Concatenate, GlobalMaxPooling1D\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm.keras import TqdmCallback\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag, ne_chunk\n",
    "import nltk.data\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
    "from nltk.chunk.util import ChunkScore\n",
    "import pickle\n",
    "import math\n",
    "import string\n",
    "#import collections.Iterable as Iterable\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "\n",
    "import gzip\n",
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, inspect, sys\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "from unwiki import unwiki\n",
    "import ner\n",
    "from embed_utils import open_w2v\n",
    "import clean_and_token_text as clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the problematic article is: examples.xml\n",
      "The name of the problematic article is: coding.xml\n",
      "The name of the problematic article is: spaces-pushouts.xml\n",
      "The name of the problematic article is: guide.xml\n",
      "The name of the problematic article is: moduli.xml\n",
      "The name of the problematic article is: more-groupoids.xml\n",
      "The name of the problematic article is: chapters.xml\n",
      "The name of the problematic article is: sets.xml\n",
      "The name of the problematic article is: obsolete.xml\n",
      "The name of the problematic article is: examples-defos.xml\n",
      "The name of the problematic article is: spaces-more-cohomology.xml\n",
      "The name of the problematic article is: bibliography.xml\n",
      "The name of the problematic article is: fdl.xml\n",
      "The name of the problematic article is: limits.xml\n",
      "The name of the problematic article is: conventions.xml\n",
      "The name of the problematic article is: introduction.xml\n",
      "The name of the problematic article is: quot.xml\n",
      "The name of the problematic article is: desirables.xml\n",
      "{'resp', 'inc', 'i.w.w', 'dha', 'ii.6.8', 'j.a', 'n.b', 'j.w', 'e.g', 'lw12', 'd.h', 'vols', 'ed', 'bald', 'cf', 'lrl', 'hd+', '. . ', 'crinem', 'd.c', 'axe', 'ch', 'forever—e.g', 'ser', 'm4', 'eur', 'ginebra', 'proc', 'juniper', 'o’s', 'jr', 'u.s.c', 'a.k.a', 'acb', 'mrs', 'ph.d', 'eq', 'r.a', 'n.v', 'a.b', 'nationality', 'pp', 'i.e', 'vs', 'p.h.d', 'r.e', 't.g', 'eng', 'i.i.d', 'rum', 'ash', 's.r', 'q.v', 'ct', 'erased', 'viz', 'feb', 'kin', 'f.h', 'spacewalks', 'u.s', 'd.r.j', 'cot', 'aa', 'phys', 'j.h.c', 'q.e.d', 'm1', 'c/mol', 'nos', 'gov', 'az', 'eqs', 'anomalies', 's.t', 'mat', 'f.s', 'o.b', 'eds', 's10', 't.f', 'g/l', 'ir', 'x+2', 'gta', 'scand', 'bat', '|c|', 'm.n', '21e', 'p.a', '62f', 'camb', 'kusala', 'a.e', 'cyan', 'w.b.r', 'w35', 'jie', 'fig', 'a.d', 'exe', 'a.s', 'k/k', 'w.e.b', '15k', 'c.s', 'c.c.c', 'p.t.f', 'j.m', 'soc', 'subpopulation', 'i.o', 'o.d', 'p.12', 'kfc', 'p.o.a', '“mr', 'hold-outs', 'c.l.r', 'nag'}\n",
      "Found 45 alphanum POS tags in the data, the most common are: [('NN', 148663), ('IN', 93211), ('DT', 90948), ('JJ', 73924), ('NNP', 49887), ('NNS', 39662), (',', 37397), ('VBZ', 36113), ('.', 26354), ('RB', 23555)]\n"
     ]
    }
   ],
   "source": [
    "#with open('/media/hd1/wikipedia/wiki_definitions_improved.txt', 'r') as wiki_f:\n",
    "#    wiki = wiki_f.readlines()\n",
    "\n",
    "cfg = {}\n",
    "\n",
    "wiki = []\n",
    "with gzip.open('/media/hd1/wikipedia/wiki_definitions_improved.xml.gz', 'r') as xml_fobj:\n",
    "    def_xml = etree.parse(xml_fobj)\n",
    "    for art in def_xml.findall('definition'):\n",
    "        data = (art.find('.//dfndum').text, '', art.find('.//stmnt').text)\n",
    "        wiki.append(data)\n",
    "\n",
    "def split_fields(elem):\n",
    "    title = elem.find('.//dfndum').text \n",
    "    section = elem.get('name')\n",
    "    defin = elem.find('.//stmnt').text\n",
    "    return (title, section, defin)\n",
    "\n",
    "plmath = []\n",
    "with gzip.open('/media/hd1/planetmath/datasets/planetmath_definitions.xml.gz', 'r') as xml_fobj:\n",
    "    def_xml = etree.parse(xml_fobj)\n",
    "    for art in def_xml.findall('article'):\n",
    "        plmath.append(split_fields(art))\n",
    "stacks = []\n",
    "with gzip.open('/media/hd1/stacks-project/datasets/stacks-definitions.xml.gz', 'r') as xml_fobj:\n",
    "    def_xml = etree.parse(xml_fobj)\n",
    "    for art in def_xml.findall('article'):\n",
    "        try:\n",
    "            stacks.append(split_fields(art))\n",
    "        except AttributeError:\n",
    "            print('The name of the problematic article is: {}'.format(art.attrib['name']))\n",
    "\n",
    "text_lst = wiki + plmath + stacks\n",
    "random.shuffle(text_lst)\n",
    "\n",
    "# Get data and train the Sentence tokenizer\n",
    "# Uses a standard algorithm (Kiss-Strunk) for unsupervised sentence boundary detection\n",
    "text = ''\n",
    "for i in range(3550):\n",
    "    text += text_lst[i][2]\n",
    "\n",
    "trainer = PunktTrainer()\n",
    "trainer.INCLUDE_ALL_COLLOCS = True\n",
    "trainer.train(text)\n",
    "sent_tok = PunktSentenceTokenizer(trainer.get_params())\n",
    "print(sent_tok._params.abbrev_types)\n",
    "\n",
    "def_lst = ner.bio_tag.put_pos_ner_tags(text_lst, sent_tok)\n",
    "\n",
    "# Finding the POS set \n",
    "pos_cnt = Counter()\n",
    "for Def in def_lst:\n",
    "    pos_cnt.update([el[0][1] for el in Def['ner']])\n",
    "print(\"Found {} alphanum POS tags in the data, the most common are: {}\"\\\n",
    "      .format(len(pos_cnt), pos_cnt.most_common()[:10]))\n",
    "pos_lst = list(pos_cnt)\n",
    "pos_ind_dict = {pos: k for k, pos in enumerate(pos_lst)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 208442 and dimension of embed: 200\n"
     ]
    }
   ],
   "source": [
    "with open_w2v('/media/hd1/embeddings/model4ner_19-33_02-01/vectors.bin') as embed_dict:\n",
    "    wind = ['<UNK>',] + list(embed_dict.keys())\n",
    "    cfg['emb_nvocab'] = len(wind) \n",
    "    embed_matrix = np.zeros((cfg['emb_nvocab'], 200))\n",
    "    for word, vec in embed_dict.items():\n",
    "        #vect = embed_dict.get(word)\n",
    "        ind = wind.index(word)\n",
    "            #vect = vect/np.linalg.norm(vect)\n",
    "        embed_matrix[ind] = vec\n",
    "#print(\"Coverage of embed is: {}\".format(coverage_cnt/len(embed_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_lengths = []\n",
    "for d in def_lst:\n",
    "    slen = min(len(d['ner']), 150)\n",
    "    sent_lengths.append(slen)\n",
    "plt.hist(sent_lengths, bins=15)\n",
    "plt.title('length of selected sentences with definiendum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Range: range(0, 26108)\n",
      " Training: range(0, 23497)  Validation: range(23497, 24802)  Test: range(24802, 26108) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg['padseq'] = {'maxlen': 50 , 'padding': 'post', 'truncating': 'post'}\n",
    "cfg['n_tags'] = 2\n",
    "\n",
    "# shuffle def_lst\n",
    "random.shuffle(def_lst)\n",
    "\n",
    "cfg['train_test_split'] = 0.9\n",
    "r_def_lst = range(len(def_lst))\n",
    "TVT_len = int(cfg['train_test_split']*len(def_lst))\n",
    "r_train = r_def_lst[:TVT_len]\n",
    "r_valid = r_def_lst[TVT_len:]\n",
    "r_test = r_valid[:int(0.5*len(r_valid))]\n",
    "r_valid = r_valid[int(0.5*len(r_valid)):]\n",
    "log_str = 'Original Range: {}\\n Training: {}  Validation: {}  Test: {} \\n'\\\n",
    "              .format(repr(r_def_lst), repr(r_train), repr(r_test), repr(r_valid)) \n",
    "print(log_str)\n",
    "\n",
    "train_def_lst = [def_lst[k] for k in r_train]\n",
    "test_def_lst = [def_lst[k] for k in r_test]\n",
    "valid_def_lst = [def_lst[k] for k in r_valid]\n",
    "\n",
    "def prep_data(dat, wind, cfg, *args):\n",
    "    '''\n",
    "   dat should be in the \"ner\" format\n",
    "    '''\n",
    "    if isinstance(dat, str):\n",
    "        dat_tok = word_tokenize(dat)\n",
    "        norm_words = [clean.normalize_text(d).strip() for d in dat_tok]\n",
    "        labels = [False for d in dat]\n",
    "    else:\n",
    "        norm_words = [clean.normalize_text(d[0][0]).strip() for d in dat]\n",
    "        labels = [d[1] != 'O' for d in dat]\n",
    "    ind_words = []\n",
    "    for w in norm_words:\n",
    "        try:\n",
    "            ind_words.append(wind.index(w))\n",
    "        except ValueError:\n",
    "            ind_words.append(0)\n",
    "    return ind_words, labels\n",
    "\n",
    "def prep_pos(dat, pos_ind_dict):\n",
    "    '''\n",
    "    dat is in the format:\n",
    "    [(('In', 'IN'), 'O'),\n",
    "     (('Southern', 'NNP'), 'O'),\n",
    "     (('Africa', 'NNP'), 'O'),\n",
    "     ((',', ','), 'O'),\n",
    "     (('the', 'DT'), 'O'),\n",
    "     (('word', 'NN'), 'O')]\n",
    "    '''\n",
    "    out_lst = []\n",
    "    for d in dat:\n",
    "        out_lst.append(pos_ind_dict[d[0][1]])\n",
    "    return out_lst\n",
    "\n",
    "#binary_fun_lst = [\n",
    "#    lambda w: word[0] in string.ascii_uppercase,  # Capitalized\n",
    "#]\n",
    "def binary_features(dat):\n",
    "    out_lst = []\n",
    "    for d in dat:\n",
    "        word =d[0][0]\n",
    "        capitalized = float(word[0] in string.ascii_uppercase)\n",
    "        contains_dash = float('-' in word)\n",
    "        \n",
    "        out_lst.append((capitalized, contains_dash))\n",
    "    return out_lst\n",
    "\n",
    "cfg['nbin_feats'] = 2 # number of binary features defined in the function above\n",
    "    \n",
    "def prep_data4real(_def_lst, wind, cfg):\n",
    "    _data = [prep_data(d['ner'], wind, cfg) for d in _def_lst]\n",
    "    _seq, _lab = zip(*_data)\n",
    "    _pos_seq = [prep_pos(d['ner'], pos_ind_dict) for d in _def_lst]\n",
    "    _bin_seq = [binary_features(d['ner']) for d in _def_lst]\n",
    "    # PAD THE SEQUENCES\n",
    "    _seq = pad_sequences(_seq, **cfg['padseq'])\n",
    "    _pos_seq = pad_sequences(_pos_seq, **cfg['padseq'])\n",
    "    _bin_seq = pad_sequences(_bin_seq, **cfg['padseq'],\n",
    "                                  value = cfg['nbin_feats']*[0.0],\n",
    "                                 dtype='float32')\n",
    "    _lab = pad_sequences(_lab, **cfg['padseq'])\n",
    "    return _seq, _pos_seq, _bin_seq, _lab\n",
    "\n",
    "train_seq, train_pos_seq, train_bin_seq , train_lab = prep_data4real(train_def_lst, wind, cfg)\n",
    "test_seq, test_pos_seq, test_bin_seq , test_lab = prep_data4real(test_def_lst, wind, cfg)\n",
    "valid_seq, valid_pos_seq, valid_bin_seq , valid_lab = prep_data4real(valid_def_lst, wind, cfg)\n",
    "\n",
    "## Create Train data\n",
    "#train_data = [prep_data(d['ner'], wind, cfg) for d in train_def_lst]\n",
    "#train_seq, train_lab = zip(*train_data)\n",
    "#train_pos_seq = [prep_pos(d['ner'], pos_ind_dict) for d in train_def_lst]\n",
    "#train_bin_seq = [binary_features(d['ner']) for d in train_def_lst]\n",
    "#cfg['nbin_feats'] = len(train_bin_seq[0][0])\n",
    "## Pad it\n",
    "#train_seq = pad_sequences(train_seq, **cfg['padseq'])\n",
    "#train_pos_seq = pad_sequences(train_pos_seq, **cfg['padseq'])\n",
    "#train_bin_seq = pad_sequences(train_bin_seq, **cfg['padseq'],\n",
    "#                              value = cfg['nbin_feats']*[0.0],\n",
    "#                             dtype='float32')\n",
    "#train_lab = pad_sequences(train_lab, **cfg['padseq'])\n",
    "##train_lab = np.array([to_categorical(s, num_classes=cfg['n_tags']) for s in train_lab])\n",
    "#\n",
    "## Create Test data\n",
    "#test_data = [prep_data(d['ner'], wind, cfg) for d in test_def_lst]\n",
    "#test_seq, test_lab = zip(*test_data)\n",
    "#test_pos_seq = [prep_pos(d['ner'], pos_ind_dict) for d in test_def_lst]\n",
    "#test_bin_seq = [binary_features(d['ner']) for d in test_def_lst]\n",
    "## Pad it\n",
    "#test_seq = pad_sequences(test_seq, **cfg['padseq'])\n",
    "#test_pos_seq = pad_sequences(test_pos_seq, **cfg['padseq'])\n",
    "#test_bin_seq = pad_sequences(test_bin_seq, **cfg['padseq'],\n",
    "#                             value = cfg['nbin_feats']*[0.0],\n",
    "#                            dtype='float32')\n",
    "#test_lab = pad_sequences(test_lab, **cfg['padseq'])\n",
    "#test_lab = np.array([to_categorical(s, num_classes=cfg['n_tags']) for s in test_lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* Right the different concatenated pieces are in different orders of magnitude. Normalization might help\n",
    "* Search for a minimal stemmer that strips plural or adverbial suffices for example zero-sum games in zero-sum game or absolute continuity and absolute continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip this\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skip this\n",
    "# Train NER model\n",
    "cfg['learning_rate'] = 0.1\n",
    "model = NerModel(64, len(word_tok.word_index)+1, 4, 100)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "def train_one_step(text_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits, text_lens, log_likelihood = model(text_batch, labels_batch, training=True)\n",
    "        loss = - tf.reduce_mean(log_likelihood)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, logits, text_lens\n",
    "\n",
    "def get_acc_one_step(logits, text_lens, labels_batch):\n",
    "    paths = []\n",
    "    accuracy = 0\n",
    "    for logit, text_len, labels in zip(logits, text_lens, labels_batch):\n",
    "        viterbi_path, _ = tfa.text.viterbi_decode(logit[:text_len], model.transition_params)\n",
    "        paths.append(viterbi_path)\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences([viterbi_path],\n",
    "                                                            padding='post'), dtype=tf.int32),\n",
    "            tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences([labels[:text_len]],\n",
    "                                                            padding='post'), dtype=tf.int32)\n",
    "        )\n",
    "        accuracy = accuracy + tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        # print(tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))\n",
    "    accuracy = accuracy / len(paths)\n",
    "    return accuracy\n",
    "\n",
    "best_acc = 0\n",
    "step = 0\n",
    "epochs = 20\n",
    "bs = 1000\n",
    "for epoch in range(epochs):\n",
    "    for (text_batch, labels_batch) in \\\n",
    "    [[train_seq2[bs*i:bs*(i+1)], train_lab2[bs*i:bs*(i+1)]]\\\n",
    "     for i in range(math.ceil(len(train_seq2)/bs))]:\n",
    "        step = step + 1\n",
    "        loss, logits, text_lens = train_one_step(text_batch, labels_batch)\n",
    "        if step % 20 == 0:\n",
    "            accuracy = get_acc_one_step(logits, text_lens, labels_batch)\n",
    "            print('epoch %d, step %d, loss %.4f , accuracy %.4f' % (epoch, step, loss, accuracy))\n",
    "            if accuracy > best_acc:\n",
    "                best_acc = accuracy\n",
    "                #ckpt_manager.save()\n",
    "                print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.update({'input_dim': len(wind),\n",
    "      'output_dim': 200,\n",
    "     'input_length': cfg['padseq']['maxlen'],\n",
    "     'pos_dim': 3,\n",
    "            'pos_constraint': 1/200,\n",
    "     'n_tags': 2,\n",
    "     'batch_size': 2000,\n",
    "     'lstm_units': 150,\n",
    "      'adam': {'lr': 0.025, 'beta_1': 0.9, 'beta_2': 0.999}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words-in (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos-in (InputLayer)             [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word-embed (Embedding)          (None, 50, 200)      41688600    words-in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pos-embed (Embedding)           (None, 50, 3)        135         pos-in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bin-features-in (InputLayer)    [(None, 50, 2)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 50, 205)      0           word-embed[0][0]                 \n",
      "                                                                 pos-embed[0][0]                  \n",
      "                                                                 bin-features-in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 50, 300)      427200      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50, 300)      541200      bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 50, 10)       3010        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 50, 1)        11          time_distributed[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 42,660,156\n",
      "Trainable params: 971,556\n",
      "Non-trainable params: 41,688,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def bilstm_lstm_model_w_pos(cfg_dict):\n",
    "    \n",
    "    words_in = Input(shape=(cfg_dict['input_length'], ), name='words-in')\n",
    "    pos_in = Input(shape=(cfg_dict['input_length'], ), name='pos-in')\n",
    "    bin_feats = Input(shape=(cfg_dict['input_length'], cfg_dict['nbin_feats']), name='bin-features-in')\n",
    "    \n",
    "    word_embed = Embedding(cfg_dict['input_dim'], \n",
    "                        output_dim=cfg_dict['output_dim'],\n",
    "                        input_length=cfg_dict['input_length'],\n",
    "                       weights = [embed_matrix],\n",
    "                       trainable = False,\n",
    "                          name='word-embed')(words_in)\n",
    "    pos_embed = Embedding(len(pos_cnt), \n",
    "                        output_dim=cfg_dict['pos_dim'],\n",
    "                        input_length=cfg_dict['input_length'],\n",
    "                          embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=1.),\n",
    "                       trainable = True,\n",
    "                         name='pos-embed')(pos_in)\n",
    "    full_embed = Concatenate(axis=2)([word_embed, pos_embed, bin_feats])\n",
    "    \n",
    "    \n",
    "    out = Bidirectional(LSTM(units=cfg['lstm_units'],\n",
    "                                 return_sequences=True,\n",
    "                                 dropout=0.2, \n",
    "                                 recurrent_dropout=0.2),\n",
    "                        merge_mode = 'concat')(full_embed)\n",
    "    #out = GlobalMaxPooling1D(out) \n",
    "    # Add LSTM\n",
    "    out = Bidirectional(LSTM(units=cfg['lstm_units'],\n",
    "                   return_sequences=True, dropout=0.2, recurrent_dropout=0.2,\n",
    "                   recurrent_initializer='glorot_uniform'),\n",
    "                        merge_mode = 'concat')(out)\n",
    "    # Add timeDistributed Layer\n",
    "    out = TimeDistributed(Dense(10, activation=\"relu\"))(out)\n",
    "    out = TimeDistributed(Dense(1, activation=\"sigmoid\"))(out)\n",
    "    #Optimiser \n",
    "    adam = Adam(**cfg['adam'])\n",
    "    # Compile model\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()  #(sample_weight=[0.3, 0.7])\n",
    "    model = Model([words_in, pos_in, bin_feats], out)\n",
    "    model.compile(loss = bce,   #'binary_crossentropy',\n",
    "                  optimizer=adam, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "with_pos = bilstm_lstm_model_w_pos(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = with_pos.fit([train_seq, train_pos_seq, train_bin_seq], train_lab, verbose=1, epochs=30,\n",
    "#                batch_size=cfg['batch_size'],\n",
    "#                validation_data=([test_seq, test_pos_seq, test_bin_seq], test_lab))\n",
    "\n",
    "# Load weights instead of fitting\n",
    "res = with_pos.load_weights('/home/luis/rm_me_data/with_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip this\n"
     ]
    }
   ],
   "source": [
    "%%script echo skip this\n",
    "# DEFINE MODEL WITH biLSTM AND TRAIN FUNCTION    \n",
    "def get_bilstm_lstm_model(cfg_dict):\n",
    "    model = Sequential()\n",
    "    # Add Embedding layer\n",
    "    model.add(Embedding(cfg_dict['input_dim'], \n",
    "                        output_dim=cfg_dict['output_dim'],\n",
    "                        input_length=cfg_dict['input_length'],\n",
    "                       weights = [embed_matrix],\n",
    "                       trainable = False))\n",
    "    #model.add(Embedding(cfg_dict['input_dim'], \n",
    "    #                    output_dim=cfg_dict['output_dim'],\n",
    "    #                    input_length=cfg_dict['input_length']))\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=cfg_dict['output_dim'],\n",
    "                                 return_sequences=True,\n",
    "                                 dropout=0.2, \n",
    "                                 recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "    # Add LSTM\n",
    "    model.add(Bidirectional(LSTM(units=cfg_dict['output_dim'],\n",
    "                   return_sequences=True, dropout=0.2, recurrent_dropout=0.2,\n",
    "                   recurrent_initializer='glorot_uniform'), merge_mode='concat'))\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(1, activation=\"sigmoid\")))\n",
    "    #Optimiser \n",
    "    adam = Adam(**cfg['adam'])\n",
    "    # Compile model\n",
    "    #bce = tf.keras.losses.BinaryCrossentropy(sample_weight=[0.3, 0.7])\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                  optimizer=adam, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(X, y, model, epochs=10):\n",
    "    # fit model for one epoch on this sequence\n",
    "    res = model.fit(X, y, verbose=0, epochs=epochs,\n",
    "                    batch_size=cfg['batch_size'],\n",
    "                    validation_data=(test_seq, test_lab),\n",
    "                   callbacks=[TqdmCallback(verbose=1)])\n",
    "                   \n",
    "    return res\n",
    "model_bilstm_lstm = get_bilstm_lstm_model(cfg)\n",
    "#plot_model(model_bilstm_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip this\n"
     ]
    }
   ],
   "source": [
    "%%script echo skip this\n",
    "history = train_model(train_seq, train_lab, model_bilstm_lstm, epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CheckpointLoadStatus' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3f44b32f485c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CheckpointLoadStatus' object has no attribute 'history'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r = history\n",
    "r = res\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.plot(r.history['loss'], label='loss')\n",
    "ax1.plot(r.history['val_loss'], label='val_loss')\n",
    "ax1.legend()\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.plot(r.history['accuracy'], label='acc')\n",
    "ax2.plot(r.history['val_accuracy'], label='val_acc')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip this\n"
     ]
    }
   ],
   "source": [
    "%%script echo skip this\n",
    "#sample_str = 'a banach space is defined as complete vector space of some kind .'\n",
    "#sample_str = 'We define a shushu space as a complete vector space of some kind .'\n",
    "sample_str = '_display_math_ The Ursell functions of a single random variable X are obtained from these by setting _inline_math_..._inline_math_ .'\n",
    "sample_pad, _ = prep_data(sample_str, wind, cfg, 'no_tags')\n",
    "sample_pad = pad_sequences([sample_pad], **cfg['padseq'])\n",
    "pred = model_bilstm_lstm.predict(sample_pad)\n",
    "#np.argmax(pred.squeeze(), axis=1)\n",
    "for i, w in enumerate(sample_pad[0]):\n",
    "    if wind[w] == '.':\n",
    "        break\n",
    "    print(wind[w], np.round(pred)[0][i])\n",
    "    if wind[w] == '.':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = model_bilstm_lstm.predict(test_seq)\n",
    "preds = with_pos.predict([test_seq, test_pos_seq, test_bin_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0324 - accuracy: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03243343159556389, 0.9883065223693848]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_pos.evaluate([test_seq, test_pos_seq, test_bin_seq], test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonetheless          O 0.00\n",
      ",                    O 0.00\n",
      "in                   O 0.00\n",
      "the                  O 0.00\n",
      "common               O 0.00\n",
      "usage                O 0.01\n",
      "the                  O 0.00\n",
      "expulsion            O 0.04\n",
      "of                   O 0.18\n",
      "foreign              O 0.37\n",
      "nationals            O 0.00\n",
      "is                   O 0.00\n",
      "usually              O 0.00\n",
      "called               O 0.00\n",
      "deportation          B-DFNDUM 0.41\n",
      ",                    O 0.00\n",
      "whereas              O 0.00\n",
      "the                  O 0.00\n",
      "expulsion            O 0.01\n",
      "of                   O 0.00\n",
      "nationals            O 0.00\n",
      "is                   O 0.00\n",
      "called               O 0.00\n",
      "extradition          O 0.45\n",
      ",                    O 0.00\n",
      "banishment           O 0.02\n",
      ",                    O 0.00\n",
      "exile                O 0.00\n",
      ",                    O 0.00\n",
      "or                   O 0.00\n",
      "penal                O 0.01\n",
      "transportation       O 0.02\n",
      ".                    O 0.00\n"
     ]
    }
   ],
   "source": [
    "k = 376\n",
    "for i in range(len(preds[k])):\n",
    "    try:\n",
    "        print('{:<20} {} {:1.2f}'.format(test_def_lst[k]['ner'][i][0][0], \n",
    "                                         test_def_lst[k]['ner'][i][1],\n",
    "                                         round(preds[k][i][0],2)))\n",
    "    except IndexError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  88.4%%\n",
      "    Precision:     63.1%%\n",
      "    Recall:        61.1%%\n",
      "    F-Measure:     62.1%%\n",
      "Cutoff:  0.5\n"
     ]
    }
   ],
   "source": [
    "def tf_bio_tagger(tf_pred, tag_def='DFNDUM', tag_o = 'O'):\n",
    "    '''\n",
    "    Convert a T/F (binary) Sequence into a BIO tag sequence\n",
    "    [True, False, False] -> [B-DFNDUM, O, O]\n",
    "    '''\n",
    "    begin_tag = 'B-' + tag_def\n",
    "    inside_tag = 'I-' + tag_def\n",
    "    out_tag = tag_o\n",
    "    return_tags = []\n",
    "    for ind, x in enumerate(tf_pred):\n",
    "        if x:\n",
    "            if ind > 0:\n",
    "                ret = inside_tag if tf_pred[ind - 1] else begin_tag\n",
    "                return_tags.append(ret)\n",
    "            else:\n",
    "                return_tags.append(begin_tag)\n",
    "        else:\n",
    "            return_tags.append(out_tag)\n",
    "    return return_tags\n",
    "        \n",
    "def switch_to_pred(test_def_lst, preds, cutoff = 0.5):\n",
    "    #if len(preds.shape) == 2:\n",
    "        #case just one prediction (50, 1) \n",
    "    #    preds = [preds]\n",
    "    out_lst = []\n",
    "    for k, pred in enumerate(preds):\n",
    "        tf_pred = (pred > cutoff)\n",
    "        test_def = test_def_lst[k]['ner']\n",
    "        bio_pred = tf_bio_tagger(tf_pred)\n",
    "        switched_def_lst = []\n",
    "        for i in range(len(bio_pred)):    #rate(bio_pred):\n",
    "            try:\n",
    "                # test_def[i] example: (('Fock', 'NNP'), 'B-DFNDUM')\n",
    "                tok_pos = test_def[i][0]\n",
    "                switched_def_lst.append((tok_pos, bio_pred[i]))\n",
    "            except IndexError:\n",
    "                break\n",
    "        out_lst.append(switched_def_lst)\n",
    "    return out_lst\n",
    "\n",
    "def get_chunkscore(CutOFF):\n",
    "    test_pred_lst = switch_to_pred(test_def_lst, preds, cutoff=CutOFF)\n",
    "    unpack = lambda l: [(tok, pos, ner) for ((tok, pos), ner) in l]\n",
    "    Tree_lst_gold = [conlltags2tree(unpack(t['ner'])) for t in test_def_lst]\n",
    "    Tree_lst_pred = [conlltags2tree(unpack(t)) for t in test_pred_lst]\n",
    "\n",
    "    chunkscore = ChunkScore()\n",
    "    for i in range(len(Tree_lst_gold)):\n",
    "        chunkscore.score(Tree_lst_gold[i], Tree_lst_pred[i])\n",
    "    return chunkscore\n",
    " \n",
    "#CutOFF = 0.4\n",
    "#print(get_chunkscore(CutOFF))\n",
    "#print(f\"Cutoff:  {CutOFF}\")\n",
    "\n",
    "data_points = []\n",
    "BOY_f_score = (0, 0) # (CutOff, score)\n",
    "for co in np.arange(0.1, 1, 0.1):\n",
    "    cs = get_chunkscore(co)\n",
    "    data_points.append((cs.accuracy(), cs.f_measure()))\n",
    "    if cs.f_measure() > BOY_f_score[1]:\n",
    "        BOY_f_score = (co, cs.f_measure())\n",
    "\n",
    "plt.plot(list(zip(*data_points))[0], label='acc')\n",
    "plt.plot(list(zip(*data_points))[1], label='F1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(get_chunkscore(BOY_f_score[0]))\n",
    "print(f\"Cutoff:  {BOY_f_score[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/5404.0*(np.sum(test_lab*np.log(np.squeeze(preds))) + np.sum((1-test_lab)*np.log(np.squeeze(1-preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load models weights\n",
    "with_pos.save_weights('/home/luis/rm_me_data/with_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words-in (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos-in (InputLayer)             [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word-embed (Embedding)          (None, 50, 200)      41688600    words-in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pos-embed (Embedding)           (None, 50, 3)        135         pos-in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bin-features-in (InputLayer)    [(None, 50, 2)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 205)      0           word-embed[0][0]                 \n",
      "                                                                 pos-embed[0][0]                  \n",
      "                                                                 bin-features-in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 50, 300)      427200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 50, 300)      541200      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 50, 10)       3010        bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 50, 1)        11          time_distributed_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 42,660,156\n",
      "Trainable params: 971,556\n",
      "Non-trainable params: 41,688,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /home/luis/rm_me_data/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /home/luis/rm_me_data/",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-edd7ee7ca223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwith_pos2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbilstm_lstm_model_w_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwith_pos2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/luis/rm_me_data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    248\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    249\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   def compile(self,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0merror_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;34m'Failed to find any '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       'matching files for') in error_message:\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n\u001b[1;32m     37\u001b[0m       \u001b[0;34m'Data type '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /home/luis/rm_me_data/"
     ]
    }
   ],
   "source": [
    "with_pos2 = bilstm_lstm_model_w_pos(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_bilstm_lstm_model Training history\n",
    "## First working attempt:  commit e4c41f0\n",
    "\n",
    "Epochs: 70 [01:00<00:00, 3.00s/epoch, loss=0.0513, accuracy=0.98, val_loss=0.0636, val_accuracy=0.975]\n",
    "\n",
    "* Same attempt but first ChunkScore Epochs: approx 80,  commit: 8a3678c\n",
    "        ChunkParse score:\n",
    "            IOB Accuracy:  86.3%%\n",
    "            Precision:     56.4%%\n",
    "            Recall:        53.8%%\n",
    "            F-Measure:     55.1%%\n",
    "            \n",
    "## Working attempt with POS: Epochs: 70\n",
    "    ChunkParse score:\n",
    "        IOB Accuracy:  85.4%%\n",
    "        Precision:     53.2%%\n",
    "        Recall:        47.6%%\n",
    "        F-Measure:     50.3%%\n",
    "### Added both LSTMs Bidirectional:\n",
    "In the previous models the second LSTM layer was not Bidirectional. This makes no sense\n",
    "loss: 0.0446 - accuracy: 0.9824 - val_loss: 0.0601 - val_accuracy: 0.9770 commit: c53ab68\n",
    "\n",
    "    ChunkParse score:\n",
    "        IOB Accuracy:  85.1%%\n",
    "        Precision:     48.7%%\n",
    "        Recall:        62.8%%\n",
    "        F-Measure:     54.9%%\n",
    "        \n",
    "With just 150 lstm units. Commit: 53dd596\n",
    "\n",
    "    ChunkParse score:\n",
    "        IOB Accuracy:  87.7%%\n",
    "        Precision:     61.4%%\n",
    "        Recall:        62.3%%\n",
    "        F-Measure:     61.8%%\n",
    "    Cutoff:  0.4\n",
    "    \n",
    "Two time dependent dense layers at the end: Commit: 2759216\n",
    "\n",
    "    ChunkParse score:\n",
    "        IOB Accuracy:  87.5%%\n",
    "        Precision:     59.5%%\n",
    "        Recall:        60.4%%\n",
    "        F-Measure:     60.0%%\n",
    "    Cutoff:  0.4\n",
    "    \n",
    "## With Binary features: capitalize, has_dash: Commit: 09c6fcb\n",
    "loss: 0.0408 - accuracy: 0.9840 - val_loss: 0.0547 - val_accuracy: 0.9789\n",
    "\n",
    "    ChunkParse score:\n",
    "        IOB Accuracy:  87.1%%\n",
    "        Precision:     59.2%%\n",
    "        Recall:        57.9%%\n",
    "        F-Measure:     58.5%%\n",
    "    Cutoff:  0.5\n",
    "    \n",
    "## Change initializer of POS embedding to Normal mean 0 std 1\n",
    "\n",
    "TBOY  loss: 0.0299 - accuracy: 0.9884 - val_loss: 0.0539 - val_accuracy: 0.9812\n",
    "\n",
    "    ChunkParse score:\n",
    "        IOB Accuracy:  87.3%%\n",
    "        Precision:     62.5%%\n",
    "        Recall:        64.2%%\n",
    "        F-Measure:     63.3%%\n",
    "    Cutoff:  0.4\n",
    "    \n",
    "loss: 0.0201 - accuracy: 0.9922 - val_loss: 0.0531 - val_accuracy: 0.9824 Commit: b3a1c88\n",
    "\n",
    "    ChunkParse score:\n",
    "    IOB Accuracy:  87.5%%\n",
    "    Precision:     68.9%%\n",
    "    Recall:        64.8%%\n",
    "    F-Measure:     66.8%%\n",
    "    Cutoff:  0.6\n",
    "\n",
    "loss: 0.0362 - accuracy: 0.9855 - val_loss: 0.0489 - val_accuracy: 0.9812 -- 40 epochs. Commit: 0530c59\n",
    "\n",
    "    ChunkParse score:\n",
    "        IOB Accuracy:  88.3%%\n",
    "        Precision:     62.2%%\n",
    "        Recall:        64.2%%\n",
    "        F-Measure:     63.2%%\n",
    "    Cutoff:  0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emb_nvocab': 208443,\n",
       " 'padseq': {'maxlen': 50, 'padding': 'post', 'truncating': 'post'},\n",
       " 'n_tags': 2,\n",
       " 'train_test_split': 0.9,\n",
       " 'nbin_feats': 2,\n",
       " 'input_dim': 208443,\n",
       " 'output_dim': 200,\n",
       " 'input_length': 50,\n",
       " 'pos_dim': 3,\n",
       " 'pos_constraint': 0.005,\n",
       " 'batch_size': 2000,\n",
       " 'lstm_units': 150,\n",
       " 'adam': {'lr': 0.025, 'beta_1': 0.9, 'beta_2': 0.999}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
